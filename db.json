{"meta":{"version":1,"warehouse":"5.0.1"},"models":{"Asset":[{"_id":"themes/typo/source/css/post.css","path":"css/post.css","modified":0,"renderable":1},{"_id":"themes/typo/source/css/root.css","path":"css/root.css","modified":1,"renderable":1},{"_id":"themes/typo/source/css/style.css","path":"css/style.css","modified":0,"renderable":1},{"_id":"themes/typo/source/js/highlight.js","path":"js/highlight.js","modified":0,"renderable":1},{"_id":"themes/typo/source/js/theme.js","path":"js/theme.js","modified":0,"renderable":1},{"_id":"themes/lx/source/favicon.ico","path":"favicon.ico","modified":0,"renderable":1},{"_id":"themes/lx/source/css/base.styl","path":"css/base.styl","modified":0,"renderable":1},{"_id":"themes/lx/source/css/custom.styl","path":"css/custom.styl","modified":0,"renderable":1},{"_id":"themes/lx/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/lx/source/images/avatar.jpeg","path":"images/avatar.jpeg","modified":0,"renderable":1},{"_id":"themes/lx/source/images/footer-l.jpeg","path":"images/footer-l.jpeg","modified":0,"renderable":1},{"_id":"themes/lx/source/images/cover.jpeg","path":"images/cover.jpeg","modified":0,"renderable":1},{"_id":"themes/lx/source/images/footer-r.jpeg","path":"images/footer-r.jpeg","modified":0,"renderable":1},{"_id":"themes/lx/source/images/post_cover.jpeg","path":"images/post_cover.jpeg","modified":0,"renderable":1},{"_id":"themes/lx/source/images/quote.svg","path":"images/quote.svg","modified":0,"renderable":1},{"_id":"themes/lx/source/js/jquery.easing.js","path":"js/jquery.easing.js","modified":0,"renderable":1},{"_id":"themes/lx/source/js/jquery.jside.menu.js","path":"js/jquery.jside.menu.js","modified":0,"renderable":1},{"_id":"themes/lx/source/js/local.search.js","path":"js/local.search.js","modified":0,"renderable":1},{"_id":"themes/lx/source/dist/css/main.min.css","path":"dist/css/main.min.css","modified":0,"renderable":1},{"_id":"themes/lx/source/dist/images/avatar.min.jpeg","path":"dist/images/avatar.min.jpeg","modified":0,"renderable":1},{"_id":"themes/lx/source/dist/images/cover.min.jpeg","path":"dist/images/cover.min.jpeg","modified":0,"renderable":1},{"_id":"themes/lx/source/dist/images/footer-l.min.jpeg","path":"dist/images/footer-l.min.jpeg","modified":0,"renderable":1},{"_id":"themes/lx/source/dist/images/footer-r.min.jpeg","path":"dist/images/footer-r.min.jpeg","modified":0,"renderable":1},{"_id":"themes/lx/source/dist/images/post_cover.min.jpeg","path":"dist/images/post_cover.min.jpeg","modified":0,"renderable":1},{"_id":"themes/lx/source/dist/images/quote.svg","path":"dist/images/quote.svg","modified":0,"renderable":1},{"_id":"themes/lx/source/dist/js/jquery.easing.min.js","path":"dist/js/jquery.easing.min.js","modified":0,"renderable":1},{"_id":"themes/lx/source/dist/js/jquery.jside.menu.min.js","path":"dist/js/jquery.jside.menu.min.js","modified":0,"renderable":1},{"_id":"themes/lx/source/dist/js/local.search.min.js","path":"dist/js/local.search.min.js","modified":0,"renderable":1},{"_id":"themes/lx/source/css/menu/button.styl","path":"css/menu/button.styl","modified":0,"renderable":1},{"_id":"themes/lx/source/css/menu/menu.styl","path":"css/menu/menu.styl","modified":0,"renderable":1},{"_id":"themes/lx/source/css/page_style/page_style.styl","path":"css/page_style/page_style.styl","modified":0,"renderable":1}],"Cache":[{"_id":"source/_posts/TUDelt硕士申请调研.md","hash":"13c06c1a2a8655341c04fba28f211243c803d924","modified":1754623007592},{"_id":"source/_posts/TMU硕士申请调研.md","hash":"492c464d83787b8e09e9932d680e8bdc161210fb","modified":1757244895943},{"_id":"source/_posts/torch的封装层次.md","hash":"937b4bad01fe0df7313721ae9618309e52164a11","modified":1757242966047},{"_id":"source/.DS_Store","hash":"0e55175cd683348e37cc91e0f8f312c2805c5ad4","modified":1758777168436},{"_id":"source/_posts/从《西征记略》看清代早期朝廷满汉语的使用.md","hash":"7babbd4c547d1cc4cbab37b46eef34a5fcc86d47","modified":1757487732702},{"_id":"source/_posts/二十年前的相机.md","hash":"e54381e5ab15cca1376091c31c23084cc192a624","modified":1757243716906},{"_id":"source/about/index.md","hash":"78f4573fe4ff02e7fbf0f91e333ae21fb284b93d","modified":1752322582311},{"_id":"source/_posts/.DS_Store","hash":"9e98dd365f8f350a42435b02ba202fd6c43b3cc3","modified":1758777168442},{"_id":"themes/typo/README.en.md","hash":"f35cb0f814b351a420212c47edadb2b08b91bbdb","modified":1738669334000},{"_id":"themes/typo/README.md","hash":"d2f7c834240511ada4b3fed3d15b144aae950bb4","modified":1738669334000},{"_id":"themes/typo/package.json","hash":"5ea19d640f24551b373dade0a9c8314af752ce27","modified":1738669334000},{"_id":"themes/typo/.DS_Store","hash":"cdf0b3dc367a4a0d2ccc072d4c8944157a50c8d4","modified":1757252352606},{"_id":"themes/typo/layout/index.ejs","hash":"94d0ac16872060f1fa1f641cd419a4902b581347","modified":1738669334000},{"_id":"themes/typo/layout/layout.ejs","hash":"a9588db85067e7094503d1f015dc92c2b2499326","modified":1738669334000},{"_id":"themes/typo/layout/archive.ejs","hash":"471055a70e5a1f6de3d072936afc2f89142b840a","modified":1738669334000},{"_id":"themes/typo/icon.svg","hash":"eb6911ca60b8c42a4433c523e751bb7226797a40","modified":1752321278230},{"_id":"themes/typo/layout/post.ejs","hash":"de2b816d655477552ab94e70f49391bb9b4b121a","modified":1738669334000},{"_id":"themes/typo/layout/_partial/footer.ejs","hash":"1f935caca6f8075486519ea93cc2270d695d24c7","modified":1738669334000},{"_id":"themes/typo/layout/_partial/head.ejs","hash":"ad8906eddcf324723bd0f881d8b3de443fc84af0","modified":1738669334000},{"_id":"themes/typo/layout/_partial/header.ejs","hash":"64ca73942d3ccfb51f15e96b81d143640c61202c","modified":1738669334000},{"_id":"themes/typo/layout/_partial/paginator.ejs","hash":"7ce58887f6601a8761333c579777ce35c8fe671f","modified":1738669334000},{"_id":"themes/typo/source/.DS_Store","hash":"e9774d2337b17b1109d6fcc3282bb58c1b355c1f","modified":1752034787144},{"_id":"themes/typo/_config.yaml","hash":"8393f2f88cc39f628ebb915041d2b5ec10f04cba","modified":1752321596028},{"_id":"themes/typo/source/js/highlight.js","hash":"4e9cab6a1aef35cf597582d17f14d027bab51200","modified":1738669334000},{"_id":"themes/typo/source/js/theme.js","hash":"2b84143778c121c875d2f4851cb0bb65f2f9f0b9","modified":1738669334000},{"_id":"themes/typo/source/css/style.css","hash":"e7890edb5f81d4581e6cd0e769a5b8c018d4a149","modified":1738669334000},{"_id":"themes/typo/source/css/root.css","hash":"c85efa24678e169e17f04570c493b3788f4ad424","modified":1738669334000},{"_id":"themes/typo/source/css/post.css","hash":"9bd3fef37862088c87f1295081a0dcaba308cdb3","modified":1738669334000},{"_id":"source/_posts/二十年前的相机/相机.jpg","hash":"df1ea692d6c7c58db02fdc17ae3f92b3388aac94","modified":1752756558542},{"_id":"source/_posts/TMU硕士申请调研/课程.png","hash":"21d6a6b5bf2f864c862f8b5dcea22cd3f9dae6ee","modified":1757243114416},{"_id":"source/_posts/二十年前的相机/内部.jpg","hash":"90712684a5c2505abb86d544b84ca2de28a827f0","modified":1752756558533},{"_id":"source/_posts/二十年前的相机/包装.jpg","hash":"60c133add5314efefbc9c93b2a90489631446266","modified":1752756558534},{"_id":"source/_posts/二十年前的相机/照片.jpg","hash":"67efc6ac23faa00d8c036ec2fe4c9a29e6d3e723","modified":1752756558536},{"_id":"public/about/index.html","hash":"3b392efdd6875617e6af2f9635a0a509cbcff789","modified":1758368711432},{"_id":"public/2025/08/07/TUDelt硕士申请调研/index.html","hash":"c647a8a4b3de5bcc97bf09f60d42a4a5873a8485","modified":1758368711432},{"_id":"public/2025/07/17/TMU硕士申请调研/index.html","hash":"7a1e1e19c6c2bf18a5f5b1ab91e3926fbb3f2ab4","modified":1758368711432},{"_id":"public/2025/07/13/二十年前的相机/index.html","hash":"df6474fef5612ca1cf3cc53886f7097ad18c10cf","modified":1758368711432},{"_id":"public/2025/07/12/torch的封装层次/index.html","hash":"8f3fc96e0cad7ee9f268f400272b80f41631d3e2","modified":1758368711432},{"_id":"public/archives/index.html","hash":"56dd7e79b4eb8c18a1cbf2894621888c0f35d9a4","modified":1758368711432},{"_id":"public/archives/2025/index.html","hash":"56dd7e79b4eb8c18a1cbf2894621888c0f35d9a4","modified":1758368711432},{"_id":"public/archives/2025/07/index.html","hash":"12da7b947ec081fc963cc020b046286c5d0dcce1","modified":1758368711432},{"_id":"public/archives/2025/08/index.html","hash":"4ec7a5b412623f89c8b2d82b4fc935496c842d05","modified":1758368711432},{"_id":"public/categories/随笔杂记/index.html","hash":"80d9d7f7ff57635bde85d6578a5e93720f1c1fcc","modified":1758368711432},{"_id":"public/categories/技术实践/index.html","hash":"8ce59e3e4acdf273a7c292d70959766c2937b0b2","modified":1758368711432},{"_id":"public/index.html","hash":"de249a06e077dc9f397d8c4946516111f2fe1e76","modified":1758368711432},{"_id":"public/tags/留学申请/index.html","hash":"23fd1658f87d1bee784c25f228a23dc244729163","modified":1758368711432},{"_id":"public/tags/转载/index.html","hash":"8416e563fe5ed0c69ea10b27ff99c9848bde5ad7","modified":1758368711432},{"_id":"public/tags/pytorch/index.html","hash":"f726b37e952a2ff724284611f9159cd388bf3872","modified":1758368711432},{"_id":"public/tags/摄影/index.html","hash":"c11e0757317c7756e56e8593faaa8c9e948ce65c","modified":1758368711432},{"_id":"public/css/post.css","hash":"9bd3fef37862088c87f1295081a0dcaba308cdb3","modified":1757245984714},{"_id":"public/css/root.css","hash":"c85efa24678e169e17f04570c493b3788f4ad424","modified":1757245984714},{"_id":"public/css/style.css","hash":"e7890edb5f81d4581e6cd0e769a5b8c018d4a149","modified":1757245984714},{"_id":"public/js/highlight.js","hash":"4e9cab6a1aef35cf597582d17f14d027bab51200","modified":1757245984714},{"_id":"public/js/theme.js","hash":"2b84143778c121c875d2f4851cb0bb65f2f9f0b9","modified":1757245984714},{"_id":"public/2025/07/13/二十年前的相机/相机.jpg","hash":"df1ea692d6c7c58db02fdc17ae3f92b3388aac94","modified":1757245984714},{"_id":"public/2025/07/17/TMU硕士申请调研/课程.png","hash":"21d6a6b5bf2f864c862f8b5dcea22cd3f9dae6ee","modified":1757245984714},{"_id":"public/assets/js/DPlayer.min.js","hash":"290283e41ac69bfd570c90800680097f998e4e0c","modified":1757245984714},{"_id":"public/2025/07/13/二十年前的相机/内部.jpg","hash":"90712684a5c2505abb86d544b84ca2de28a827f0","modified":1757245984714},{"_id":"public/2025/07/13/二十年前的相机/包装.jpg","hash":"60c133add5314efefbc9c93b2a90489631446266","modified":1757245984714},{"_id":"public/2025/07/13/二十年前的相机/照片.jpg","hash":"67efc6ac23faa00d8c036ec2fe4c9a29e6d3e723","modified":1757245984714},{"_id":"public/2025/07/17/从《西征记略》看清代早期朝廷满汉语的使用/index.html","hash":"9978f29bf9118c5351fcb453887bcf52a879ed64","modified":1758368711432},{"_id":"themes/hexo-theme-simple99/.DS_Store","hash":"2c3f928dd642ea886777fb4bfd7925bec5f4406b","modified":1757252357293},{"_id":"themes/hexo-theme-simple99/.gitignore","hash":"93129d7d709c615a4b1cb50c0cca2e810bf179f8","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/.bowerrc","hash":"5d8502d31f0ed07e935bc6faf5e7f8ce8308ab75","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/LICENSE","hash":"89015a07b19c1ce53cd3a4120e1cb2a357f9f6e9","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/package.json","hash":"2d6234da845e8743515c8aad45d3df8834dfe2de","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/README-zh.md","hash":"3efacc564355dd7620bfaefe35268af46e02384e","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/README.md","hash":"fe49162707ea8d4426b2a0f6e87c98f3d3b82679","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/bower.json","hash":"756d74bd0aa7e112f9e84e84285bacd195f167c4","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/_config.yml","hash":"affcb2582411180f5a12f5558a20268782efb713","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/languages/zh-CN.yml","hash":"ba30a9c463a33bfafdda6044f1f2ba54afd4e91d","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/index.ejs","hash":"6e9085bb10d797edce98c32c4b6252d613e97fc6","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/layout.ejs","hash":"39450cd577297247de720644826b75cb4aad8eb8","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/about.ejs","hash":"ae8d35e12f9a093a83f0cece6797de2c7de6ab48","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/archive.ejs","hash":"5b0b5ea4d40377a2866822ef0fb18c10a8337584","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/category.ejs","hash":"a8eaa292446b1685ffbff57ce2836e72b5e54791","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/message.ejs","hash":"dd4a2b56fee7efe70b54286800523fab052cf210","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/tag.ejs","hash":"598b83b464d197f78baa57b6374feb313beb06af","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/page.ejs","hash":"5ebd3010206439bc5482eea1af13cdb80f6b7830","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/.DS_Store","hash":"fa8428a5696b808f07e3b857497d91d45d1f2819","modified":1757252336343},{"_id":"themes/hexo-theme-simple99/layout/partials/analytics.ejs","hash":"6ba133799ac450635c99e25f6d2463d1dafc11a7","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/partials/article-copy-code.ejs","hash":"0fe6bf593ae4ca8c8c0e5f498050e2c4566285c6","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/partials/comments.ejs","hash":"8c3e9cc5f2ad8c117ca1293f30c9d0ac2eb9eeb6","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/post.ejs","hash":"d61c476775effbb4104d39cdfeeeda4ab06e4f7b","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/search.ejs","hash":"08775c59f4956e0c0e610003f6dacd847fa63c5c","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/partials/copyright.ejs","hash":"1a0a96e135134e74231266b3fefdd6bfd1072106","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/partials/pagination.ejs","hash":"0580020eb197c2cf57e573028967e2bfd8770de7","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/partials/head.ejs","hash":"56bce6051d28d9e9d28385b941be4006e4443a23","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/partials/footer.ejs","hash":"4f122c91613b057b209535a28387a7807f7506cd","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/partials/widgets.ejs","hash":"19a491a88a675cbbaeb2cca7967c78e131411cb9","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/partials/theme.ejs","hash":"233e922b31fa33397e42bc8e6e29d21352ebe17d","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/partials/title_list.ejs","hash":"ccb3a6e7bd87ed41aa8ca90b9bd00f091887dc6b","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/widget/archive.ejs","hash":"38a6b8e044490077269a0127b82d74b59515aee6","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/partials/nav.ejs","hash":"a00a9fa5e5df140610a8deba581334aa1885bebd","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/.DS_Store","hash":"51717f6e82c5025c265c69b8b26b1c8338a6b9d7","modified":1757252336345},{"_id":"themes/hexo-theme-simple99/layout/widget/links.ejs","hash":"dd74523d6ea2eab726a6b880e21d4ab9aeba1847","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/widget/category.ejs","hash":"60ed17e077e54ccd5b0280dc4f7ad5fd2fabdff1","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/widget/notice.ejs","hash":"6daf4623c471704d805927c577f0a3f0aa6ffd6b","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/widget/recent_posts.ejs","hash":"d0b3ff666b750eff8f8746e93da9c721e48b405f","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/layout/widget/tag.ejs","hash":"2de380865df9ab5f577f7d3bcadf44261eb5faae","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/css/highlight.css","hash":"631a7ef33a38cd4f438c7a33df5feaae6b46e4d8","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/css/jquery.tocify.css","hash":"a274d92392cb4fe0f8fb339a5f20b3d82fe495c8","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/css/nav-icon.css","hash":"6786f6535ab99182e59c6c25a52dac602f5efb27","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/css/nav-indicator.css","hash":"4648f75060594841bcca07ebeaf99bd719f8e3d6","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/css/highlight.light.css","hash":"3b945b847eb30f29828897308cb1efc31199b2d0","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/css/preloader.css","hash":"6a64d0102ab21502b0ac11ca635a917f14c7cb73","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/css/prism-customize.css","hash":"72636b7fa2c61137e881fcfbf0914fbbdf9c8ab9","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/css/search.css","hash":"b4e0254ca4c8bb10f35e6bd334b307456046c11c","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/css/twikoo.css","hash":"9da04f551ce05ed71525f89ca385f90164bc8caa","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/css/waves.min.css","hash":"6cd49978e819697627009a205a85f2ff0e0a009c","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/js/comment.js","hash":"15175fbb2cdffbdafb40a3106381d715373e4afd","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/css/smooth-state-anim.css","hash":"29d6e7f5f4973e1286e9fceea7c145fe6eb2c65f","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/js/copy.js","hash":"89e7a3e73f566b0bce1fb6bd340f8f8a994c48f5","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/css/main.css","hash":"e80802c8d7bd525baf365c9f0df8bdbf67e88ba9","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/js/search.js","hash":"3c346defdf66558f84f951d4034210ed07739714","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/js/main.js","hash":"81fcc1155de54ebe9d9c621e21301b68582a95bb","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/lib/main.js","hash":"8e9cdcffeb37893456df2f871d6b31ba8697964e","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/lib/waves.js","hash":"3fe0509fbbf82fe340bfe86e7ddb7bda8b1ae309","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/lib/jquery.tocify.js","hash":"a5b430cde9568b6fcccfc0deb61cd287c1b1017e","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/lib/waves.min.js","hash":"9b955c7464e32ef9c641537b2e9bc3e50506a3a7","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/lib/jquery.tocify.min.js","hash":"b57e1570be4599b7b1e28a21cad309345f081571","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/css/animate.css","hash":"706475f47013d79b7e7cbe84e3cda2b52b18875d","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/lib/jquery.js","hash":"3b0f35285a7088b1fd321773696f9d3b45d31942","modified":1634048624000},{"_id":"themes/hexo-theme-simple99/source/lib/jquery-ui.js","hash":"8689f0993aa736965899d1e3bbe40c3378416191","modified":1634048624000},{"_id":"public/css/highlight.css","hash":"631a7ef33a38cd4f438c7a33df5feaae6b46e4d8","modified":1757340447585},{"_id":"public/css/jquery.tocify.css","hash":"a274d92392cb4fe0f8fb339a5f20b3d82fe495c8","modified":1757340447585},{"_id":"public/css/animate.css","hash":"706475f47013d79b7e7cbe84e3cda2b52b18875d","modified":1757340447585},{"_id":"public/css/main.css","hash":"f8036b615c6bcb2646f5f7cdcdd17aaaccfb4460","modified":1757341413738},{"_id":"public/css/nav-icon.css","hash":"6786f6535ab99182e59c6c25a52dac602f5efb27","modified":1757340447585},{"_id":"public/css/nav-indicator.css","hash":"4648f75060594841bcca07ebeaf99bd719f8e3d6","modified":1757340447585},{"_id":"public/css/preloader.css","hash":"6a64d0102ab21502b0ac11ca635a917f14c7cb73","modified":1757340447585},{"_id":"public/css/prism-customize.css","hash":"72636b7fa2c61137e881fcfbf0914fbbdf9c8ab9","modified":1757340447585},{"_id":"public/css/highlight.light.css","hash":"3b945b847eb30f29828897308cb1efc31199b2d0","modified":1757340447585},{"_id":"public/css/search.css","hash":"b4e0254ca4c8bb10f35e6bd334b307456046c11c","modified":1757340447585},{"_id":"public/css/smooth-state-anim.css","hash":"29d6e7f5f4973e1286e9fceea7c145fe6eb2c65f","modified":1757340447585},{"_id":"public/css/twikoo.css","hash":"9da04f551ce05ed71525f89ca385f90164bc8caa","modified":1757340447585},{"_id":"public/css/waves.min.css","hash":"6cd49978e819697627009a205a85f2ff0e0a009c","modified":1757340447585},{"_id":"public/js/comment.js","hash":"15175fbb2cdffbdafb40a3106381d715373e4afd","modified":1757340447585},{"_id":"public/js/copy.js","hash":"89e7a3e73f566b0bce1fb6bd340f8f8a994c48f5","modified":1757340447585},{"_id":"public/js/main.js","hash":"81fcc1155de54ebe9d9c621e21301b68582a95bb","modified":1757340447585},{"_id":"public/js/search.js","hash":"3c346defdf66558f84f951d4034210ed07739714","modified":1757340447585},{"_id":"public/lib/jquery.tocify.js","hash":"a5b430cde9568b6fcccfc0deb61cd287c1b1017e","modified":1757340447585},{"_id":"public/lib/jquery.tocify.min.js","hash":"b57e1570be4599b7b1e28a21cad309345f081571","modified":1757340447585},{"_id":"public/lib/main.js","hash":"8e9cdcffeb37893456df2f871d6b31ba8697964e","modified":1757340447585},{"_id":"public/lib/jquery.js","hash":"3b0f35285a7088b1fd321773696f9d3b45d31942","modified":1757340447585},{"_id":"public/lib/waves.js","hash":"3fe0509fbbf82fe340bfe86e7ddb7bda8b1ae309","modified":1757340447585},{"_id":"public/lib/waves.min.js","hash":"9b955c7464e32ef9c641537b2e9bc3e50506a3a7","modified":1757340447585},{"_id":"public/lib/jquery-ui.js","hash":"8689f0993aa736965899d1e3bbe40c3378416191","modified":1757340447585},{"_id":"themes/lx/.gitignore","hash":"3ca0e72fdfd533e411cc95dc9c91c5ec59661f95","modified":1693191998000},{"_id":"themes/lx/CODE_OF_CONDUCT.md","hash":"4faa826cb7049aff196edbf38e0b29c3fec2cf17","modified":1693191998000},{"_id":"themes/lx/.editorconfig","hash":"f8102695960fe708149c2e21934969700bfb0031","modified":1693191998000},{"_id":"themes/lx/LICENSE","hash":"2e43fe50cb85afda5cbd30aa4c056125f0e11a53","modified":1693191998000},{"_id":"themes/lx/CONTRIBUTING.md","hash":"c70e994eb59d431ccaaf8b114ad74c8962cc3f45","modified":1693191998000},{"_id":"themes/lx/.DS_Store","hash":"c3b70edda7373bfaeb1c89d225de430838320f62","modified":1757252336346},{"_id":"themes/lx/package.json","hash":"ca62ff35b77d45eda766c5ffef51e5e79328a5b8","modified":1693191998000},{"_id":"themes/lx/gulpfile.js","hash":"1800ec5b8076404d7bd014964d48471307ec4125","modified":1693191998000},{"_id":"themes/lx/_config.yml","hash":"8671a3c1153ac6144c6ed62a6973a956aa9acb03","modified":1757488206198},{"_id":"themes/lx/README.md","hash":"b5f12f0acb9ce0ec6529592382926db3f88b06f9","modified":1693191998000},{"_id":"themes/lx/languages/zh.yml","hash":"b9a174e46bd89df7d6bf3a7863c350a62dce8a81","modified":1693191998000},{"_id":"themes/lx/README/README.zh.md","hash":"2d0572ac20d681eaecbcaf8b401291428791bc90","modified":1693191998000},{"_id":"themes/lx/.github/.DS_Store","hash":"030c8546a0738cced601a23ec3f9058ab2ff4b32","modified":1757251158401},{"_id":"themes/lx/languages/en.yml","hash":"ec59da08e7c8dc61872b7896f167e42491965b2e","modified":1693191998000},{"_id":"themes/lx/.github/FUNDING.yml","hash":"21bed4e222cde27dc5875bfe39ce76165d519d71","modified":1693191998000},{"_id":"themes/lx/layout/index.ejs","hash":"6c73bb34c29861124a0464a9a8dea95adf4fc5b0","modified":1693191998000},{"_id":"themes/lx/layout/archive.ejs","hash":"539ad764457af4434a6764c2044c4bbb9c34759f","modified":1693191998000},{"_id":"themes/lx/layout/post.ejs","hash":"9396418ae3822ee444f44c509ec27955842c9360","modified":1693191998000},{"_id":"themes/lx/layout/.DS_Store","hash":"affd85d8bf0276d45d987ee3e612e68d70add11b","modified":1757251158408},{"_id":"themes/lx/layout/page.ejs","hash":"c0895bd2b63c5bba7c54686d6b7eaec9fbc520a5","modified":1693191998000},{"_id":"themes/lx/source/favicon.ico","hash":"96b9a549337c2bec483c2879eeafa4d1f8748fed","modified":1693191998000},{"_id":"themes/lx/scripts/.DS_Store","hash":"f74ea4192b474e53580d548552fc3e2e2079e25b","modified":1757251158403},{"_id":"themes/lx/source/.DS_Store","hash":"1df9ce9cc4328e9299c7f31184699a7ca7b487c9","modified":1757251158406},{"_id":"themes/lx/.github/ISSUE_TEMPLATE/--------feature-request.md","hash":"14c1b9b0234e1930cdcb5effade695dd8ed96378","modified":1693191998000},{"_id":"themes/lx/layout/layout.ejs","hash":"264f3c78aa37e08273a62de5e2cddae87ca5e25a","modified":1693191998000},{"_id":"themes/lx/.github/ISSUE_TEMPLATE/------help-wanted.md","hash":"5d71620c4feb15de44248dc1bbfef0bdb83ff080","modified":1693191998000},{"_id":"themes/lx/.github/workflows/greetings.yml","hash":"e96db36e14850b776b6db0b20c1c3a5decb7ecf8","modified":1693191998000},{"_id":"themes/lx/.github/ISSUE_TEMPLATE/------bug-bug-report.md","hash":"31d326cf90434637cc1223d1272f3db6913c1bc0","modified":1693191998000},{"_id":"themes/lx/layout/partials/aside.ejs","hash":"86d29f00d2a2e5fba2d79fa8897dca5f96e7dd4e","modified":1693191998000},{"_id":"themes/lx/layout/partials/font.ejs","hash":"2dc65c0b4f60ed8329a296c5172aee8d42025a1e","modified":1693191998000},{"_id":"themes/lx/layout/partials/config.ejs","hash":"6809577629e67dc00a2b20c2326818fa7f2c29be","modified":1693191998000},{"_id":"themes/lx/.github/workflows/main.yml","hash":"be47e533b91c648e46825a9dd6e494aa309b3866","modified":1693191998000},{"_id":"themes/lx/layout/partials/footer.ejs","hash":"cada2b375642f0e6485eeaaf023df6c8f4529ded","modified":1693191998000},{"_id":"themes/lx/layout/partials/post-footer.ejs","hash":"58af93593736cc562c73fb92f2468bc71cc8f9e6","modified":1693191998000},{"_id":"themes/lx/layout/partials/menu.ejs","hash":"7c3d71999f233f5fb7549a472c922c8257711d5f","modified":1693191998000},{"_id":"themes/lx/layout/partials/post-header.ejs","hash":"dcdc9c03e3e7df0a62201996822daae03236e18e","modified":1693191998000},{"_id":"themes/lx/layout/partials/recent-posts.ejs","hash":"889018a6df0c62b61c1c03712a2d3eb39882559c","modified":1693191998000},{"_id":"themes/lx/layout/partials/search-button.ejs","hash":"782b1b367b7f90211e84a90d4f8bb3f3bf923a88","modified":1693191998000},{"_id":"themes/lx/.github/workflows/stable_test.yml","hash":"ab02fc3eb150745861b6ccb1c74fd8334eecfd9a","modified":1693191998000},{"_id":"themes/lx/scripts/tags/button.js","hash":"dd5da28768a3ed3f2e3b308a9ff220403825579f","modified":1693191998000},{"_id":"themes/lx/layout/partials/pagination.ejs","hash":"82c25643c1e3b16f0472eebfe77f4a03ad0e8824","modified":1693191998000},{"_id":"themes/lx/scripts/tags/label.js","hash":"7247ac0f614993d4d162b14b68e924fc969581f5","modified":1693191998000},{"_id":"themes/lx/layout/partials/search.ejs","hash":"805e680af358cb1f4252f83766135ebd82e52183","modified":1693191998000},{"_id":"themes/lx/scripts/tags/note.js","hash":"19dc88f867d684101e851e25fe9da661c56acc66","modified":1693191998000},{"_id":"themes/lx/scripts/tags/center-quote.js","hash":"e5086a9b99ac1c8006f4fa7c5568b96cc1d47cf6","modified":1693191998000},{"_id":"themes/lx/scripts/tags/video.js","hash":"3a70f28b9769fd308c8df7d694fb7f896f12ae58","modified":1693191998000},{"_id":"themes/lx/scripts/helpers/font.js","hash":"0fc8635261ceacd26a57537e356bcfce2bd4b89b","modified":1693191998000},{"_id":"themes/lx/layout/third-party/mathjax.ejs","hash":"e857f83195594e6ffcacf08f07df0c229806113b","modified":1693191998000},{"_id":"themes/lx/layout/partials/sociallinks.ejs","hash":"60c0e2ac3d7afe6cb7d38b31dddd5c2e4e6cca21","modified":1693191998000},{"_id":"themes/lx/layout/third-party/comment.ejs","hash":"f1d1c9425059e76c8481829797de44df637c0723","modified":1693191998000},{"_id":"themes/lx/source/css/base.styl","hash":"afebc653fcfc7c5566f50f61b79d5a3c9b89b209","modified":1693191998000},{"_id":"themes/lx/source/css/custom.styl","hash":"ea4354df3981777b4478f4207efddabf707d6df4","modified":1693191998000},{"_id":"themes/lx/source/css/main.styl","hash":"f6e3c3777737426ccce75be40e6ec3aaf1a991f6","modified":1693191998000},{"_id":"themes/lx/source/images/footer-l.jpeg","hash":"f036edc5f66ffbcc34c3d855414c6ca5ef30a04b","modified":1693191998000},{"_id":"themes/lx/source/images/quote.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1693191998000},{"_id":"themes/lx/source/js/jquery.easing.js","hash":"af83a43279779fbc716f40ba8c5280782027540a","modified":1693191998000},{"_id":"themes/lx/source/images/avatar.jpeg","hash":"6372d01c2e4f5f94e460e7aa7b8c205dcaf7ddc4","modified":1693191998000},{"_id":"themes/lx/source/images/footer-r.jpeg","hash":"5c7677ac85cf8a683b91e97702b7096017006b4f","modified":1693191998000},{"_id":"themes/lx/layout/third-party/analytics/baidu-analytics.ejs","hash":"30cf8cd193777b1e071313528e06b16eca508187","modified":1693191998000},{"_id":"themes/lx/layout/third-party/analytics/index.ejs","hash":"c98b574b2634de33694edb40b1f9120160b81acb","modified":1693191998000},{"_id":"themes/lx/source/js/jquery.jside.menu.js","hash":"90861969a85b8ae034415820d732e33c9d63a5e3","modified":1693191998000},{"_id":"themes/lx/layout/third-party/analytics/google-analytics.ejs","hash":"09775c366a01c656b7185ef3da4bc7b33caa2241","modified":1693191998000},{"_id":"themes/lx/source/images/post_cover.jpeg","hash":"93f216636c87dbbe635d4bb6b944851d92d84723","modified":1693191998000},{"_id":"themes/lx/source/js/local.search.js","hash":"8d24f3f958a094f2a692b614b52f4143fa2a2c18","modified":1693191998000},{"_id":"themes/lx/source/dist/css/main.min.css","hash":"0d97924e53180149a02486b2075d5f17a56b0d9f","modified":1693191998000},{"_id":"themes/lx/source/dist/images/footer-l.min.jpeg","hash":"99e7d490bd28f87c247204cb3b517f335e07b25f","modified":1693191998000},{"_id":"themes/lx/source/dist/images/post_cover.min.jpeg","hash":"3de3124894068f0e2dbc52452da0897f556924ef","modified":1693191998000},{"_id":"themes/lx/source/dist/images/quote.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1693191998000},{"_id":"themes/lx/source/dist/images/avatar.min.jpeg","hash":"c074425477cdac61cb130a85fd6da333007f4ae2","modified":1693191998000},{"_id":"themes/lx/source/dist/js/jquery.jside.menu.min.js","hash":"2c8cc3842f362c8a63f8cc52dcdf227971615538","modified":1693191998000},{"_id":"themes/lx/source/dist/images/footer-r.min.jpeg","hash":"bab03d4eca9d0f0e835c01bbd8e67621cb5d44a3","modified":1693191998000},{"_id":"themes/lx/source/dist/js/jquery.easing.min.js","hash":"a4228d2b0d48fd796debeef146534d97d3531742","modified":1693191998000},{"_id":"themes/lx/source/css/menu/button.styl","hash":"1ebc848957f27f720e7b3bec23919cc08f54367b","modified":1693191998000},{"_id":"themes/lx/source/css/menu/menu.styl","hash":"c47a8e0511a72829f501a1f440a47f2ed267c3fe","modified":1693191998000},{"_id":"themes/lx/source/css/page_style/page_style.styl","hash":"7556e80299c999504d50e2e4d5ce590ed48e4c89","modified":1693191998000},{"_id":"themes/lx/source/dist/js/local.search.min.js","hash":"84983a5382d6c0293289ad5a944ea7f58dcfba5c","modified":1693191998000},{"_id":"themes/lx/source/dist/images/cover.min.jpeg","hash":"ddb39341e9b5555c250029b0ca4cd4cfe80522bf","modified":1693191998000},{"_id":"themes/lx/source/images/cover.jpeg","hash":"186350a358c03649b83d5501ee43c90b1cc1160e","modified":1693191998000},{"_id":"themes/lx/package-lock.json","hash":"f5dfcfe16e0e73408e857e25bf96fde6c1306725","modified":1693191998000},{"_id":"public/search.xml","hash":"5b363ec85b7d788a34201bcb148348a37fc46629","modified":1758368711432},{"_id":"public/images/footer-l.jpeg","hash":"f036edc5f66ffbcc34c3d855414c6ca5ef30a04b","modified":1757341413738},{"_id":"public/favicon.ico","hash":"96b9a549337c2bec483c2879eeafa4d1f8748fed","modified":1757341413738},{"_id":"public/images/footer-r.jpeg","hash":"5c7677ac85cf8a683b91e97702b7096017006b4f","modified":1757341413738},{"_id":"public/images/post_cover.jpeg","hash":"93f216636c87dbbe635d4bb6b944851d92d84723","modified":1757341413738},{"_id":"public/images/quote.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1757341413738},{"_id":"public/dist/images/avatar.min.jpeg","hash":"c074425477cdac61cb130a85fd6da333007f4ae2","modified":1757341413738},{"_id":"public/dist/images/footer-l.min.jpeg","hash":"99e7d490bd28f87c247204cb3b517f335e07b25f","modified":1757341413738},{"_id":"public/dist/images/footer-r.min.jpeg","hash":"bab03d4eca9d0f0e835c01bbd8e67621cb5d44a3","modified":1757341413738},{"_id":"public/dist/images/post_cover.min.jpeg","hash":"3de3124894068f0e2dbc52452da0897f556924ef","modified":1757341413738},{"_id":"public/dist/images/quote.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1757341413738},{"_id":"public/images/avatar.jpeg","hash":"6372d01c2e4f5f94e460e7aa7b8c205dcaf7ddc4","modified":1757341413738},{"_id":"public/images/cover.jpeg","hash":"186350a358c03649b83d5501ee43c90b1cc1160e","modified":1757341413738},{"_id":"public/dist/images/cover.min.jpeg","hash":"ddb39341e9b5555c250029b0ca4cd4cfe80522bf","modified":1757341413738},{"_id":"public/css/custom.css","hash":"ea4354df3981777b4478f4207efddabf707d6df4","modified":1757341413738},{"_id":"public/css/base.css","hash":"6d884ebc4f4c1a7c750e4b871ecfff6c28b47ed0","modified":1757341413738},{"_id":"public/js/jquery.easing.js","hash":"af83a43279779fbc716f40ba8c5280782027540a","modified":1757341413738},{"_id":"public/js/jquery.jside.menu.js","hash":"12d569674bcdac0bab4ce532c808656181bdba8e","modified":1757341413738},{"_id":"public/js/local.search.js","hash":"8d24f3f958a094f2a692b614b52f4143fa2a2c18","modified":1757341413738},{"_id":"public/dist/js/jquery.easing.min.js","hash":"a4228d2b0d48fd796debeef146534d97d3531742","modified":1757341413738},{"_id":"public/dist/js/jquery.jside.menu.min.js","hash":"2c8cc3842f362c8a63f8cc52dcdf227971615538","modified":1757341413738},{"_id":"public/dist/css/main.min.css","hash":"0d97924e53180149a02486b2075d5f17a56b0d9f","modified":1757341413738},{"_id":"public/css/menu/menu.css","hash":"2af419715d90b59d6e864c0bccfc520bcc6d84ea","modified":1757341413738},{"_id":"public/css/menu/button.css","hash":"d8b90561a3d1366e8f5b78c61937ec9e6b387029","modified":1757341413738},{"_id":"public/css/page_style/page_style.css","hash":"faf5508533d035e3bfc9c15019fa34f1275a1908","modified":1757341413738},{"_id":"public/dist/js/local.search.min.js","hash":"84983a5382d6c0293289ad5a944ea7f58dcfba5c","modified":1757341413738},{"_id":"source/_posts/一首小诗.md","hash":"66b63bf4e613a9799bbe2c177d4dff2763ab9a26","modified":1758367928324},{"_id":"public/2025/09/12/一首小诗/index.html","hash":"afc2f4bc20dd539dbcc030f2a5aae9f3e961c017","modified":1758368711432},{"_id":"public/archives/2025/09/index.html","hash":"6978256fde0ebf6af9ddb58a9dfed2680dc55fb5","modified":1758368711432},{"_id":"public/tags/随笔杂记/index.html","hash":"0b077d3c40b233d64cd81d79b57a7bd75a5ec11d","modified":1758368711432}],"Category":[{"name":"随笔杂记","_id":"cmf9mvzsu0003ad9l3cmyhcus"},{"name":"技术实践","_id":"cmf9mvzsx000bad9l3vd82zc0"},{"name":"log","_id":"cmgm3ckq40000y69lhbs55341"},{"name":"日志","_id":"cmgm3eywy0002y69l3flr3rff"},{"name":"转载","_id":"cmgm3gosy0004y69l94vk1245"},{"name":"随笔","_id":"cmgm3gpej0006y69l1ndi4oap"}],"Data":[],"Page":[{"title":"about","date":"2025-07-12T12:00:32.000Z","_content":"> 造一个草原  \n> 需要一株苜蓿和一只蜜蜂  \n> 一株苜蓿、一只蜜蜂——\n> 再加一个梦\n> 要是蜜蜂少\n> 光有梦  \n> 也成  \n","source":"about/index.md","raw":"---\ntitle: about\ndate: 2025-07-12 20:00:32\n---\n> 造一个草原  \n> 需要一株苜蓿和一只蜜蜂  \n> 一株苜蓿、一只蜜蜂——\n> 再加一个梦\n> 要是蜜蜂少\n> 光有梦  \n> 也成  \n","updated":"2025-07-12T12:16:22.311Z","path":"about/index.html","comments":1,"layout":"page","_id":"cmf9mvzsr0000ad9l86ky5lwc","content":"<blockquote>\n<p>造一个草原<br>需要一株苜蓿和一只蜜蜂<br>一株苜蓿、一只蜜蜂——<br>再加一个梦<br>要是蜜蜂少<br>光有梦<br>也成  </p>\n</blockquote>\n","excerpt":"","more":"<blockquote>\n<p>造一个草原<br>需要一株苜蓿和一只蜜蜂<br>一株苜蓿、一只蜜蜂——<br>再加一个梦<br>要是蜜蜂少<br>光有梦<br>也成  </p>\n</blockquote>\n"}],"Post":[{"title":"TMU硕士申请调研","date":"2025-07-17T12:37:37.000Z","_content":"### 资料来源\n\n本文所有资料均来自于TMU官网中[School of Computation,Information and Technology板块](https://www.cit.tum.de/en/cit/home/)，以下简称CIT学院。\n其中具体信息主要来自于其中的[学位项目板块](https://www.cit.tum.de/en/cit/studies/degree-programs/)\n\n### 硕士学制\n\n标准学制2年，以课程为主\n\n### 在当地工作\n\n毕业后到慕尼黑外国人事务局（KVR）把原来的学生居留直接换成“18 个月求职居留”（§ 16b Abs. 4 AufenthG）。\n在这 18 个月内可以无限制打工（不限天数、不限行业），以维持生活并积累相关经验\n找到与学位匹配的“合格工作”后，可立即把求职居留转换成“就业居留”（§ 18b AufenthG）。\n只要这份工作持续 24 个月、并缴纳社保，且德语达到 A1，就能申请德国永久居留。[pdf说明文件](https://www.community.tum.de/wp-content/uploads/2023/04/TU_Flyer_WorkingInGermany2023_WEB.pdf)\n\n总的而言，德国还是有一定IT缺口的。\n\n# CIT本科专业\n\n信息来自于[学位项目板块](https://www.cit.tum.de/en/cit/studies/degree-programs/)\n\n### 本科信息学（Informatics）培养方案（用于检查课程匹配度）\n\n[课程网址](https://www.cit.tum.de/cit/studium/studiengaenge/bachelor-informatik/studienplan/)\n本科培养方案要求翻译如下：\n{% asset_img \"课程.png\"%}\n对个人而言，这个专业是最契合国内本科计算机科学专业培养方案的。\n\n### 本科信息工程（Information Engineering）培养方案\n\n[官网文件](https://www.cit.tum.de/fileadmin/w00byx/cit/Studium/Studiengaenge/Bachelor_Information_Engineering_Heilbronn/20221213_Studiengangsdokumentation_BSc_IE_Teil_A_AbgabeSenat__1_.pdf)\n主要内容翻译如下：\n\n| 类别                                                   | 学分  | 说明                                           |\n| ------------------------------------------------------ | ----- | ---------------------------------------------- |\n| **必修：计算机科学**                             | 90 CP | 信息学核心课程                                 |\n| **必修：数学**                                   | 36 CP | 离散结构、线性代数、微积分、概率论             |\n| **选修：计算机科学**                             | 12 CP | 从实时系统、虚拟机、密码学等模块中选 2 门      |\n| **选修：经济/管理**                              | 18 CP | 财务会计、管理科学、物流与生产等 3 门          |\n| **选修：跨学科/软技能**                          | 9 CP  | 伦理、创业、跨文化沟通等                       |\n| **毕业论文 + 答辩**                              | 15 CP | 第 6 学期完成（12 CP 论文 + 3 CP 答辩）        |\n| **必修实践项目**                                 | 10 CP | 第 5 学期小组项目（Bachelor Practical Course） |\n| **必修研讨课**                                   | 5 CP  | 第 3 学期独立完成科研小课题                    |\n| 添加了一些经管类课程，其他本科专业大同小异，不再赘述。 |       |                                                |\n\n# CIT硕士专业  \n全部信息来自于[学位项目板块](https://www.cit.tum.de/en/cit/studies/degree-programs/)\n\n### 信息学(Informatics)硕士专业\n- [主页](https://www.cit.tum.de/en/cit/studies/degree-programs/master-informatics/)\n- 语言：英语\n- 申请期限\n  - 冬季学期：2月1日至5月31日\n  - 夏季学期：9月1日至11月30日\n- 申请流程[参考](https://www.tum.de/en/studies/application/master/application-master)\n  - [注册](https://campus.tum.de/tumonline/)\n  - 能力评估\n    - 在初始阶段，您在学士学位课程中获得的成绩以及您的书面文件将使用积分系统进行评估。根据累积的积分数量，申请人要么立即被录取，要么被拒绝，要么被邀请参加该部门进行的20分钟的招生面试。在某些情况下，对国际学生进行电话面试。\n    - 面试代表了程序的第二阶段，有助于确定申请人是否能够成功完成所需的学习课程。您可以在您期望的学位课程的学术和考试条例的附录2中找到更多信息。\n  - GRE分数要求：\n    Applicants with a Degree from Bangladesh, China, India, Iran or Pakistan have to submit a GRE (General) Test. We have defined required minimum scores, lower scores will not be accepted!\n    The required scores are:\n    Verbal reasoning: (will not be taken into account anymore)\n    Quantitative reasoning: 164\n    Analytical writing: 4.0  \n    即：数学要求164，写作要求4.0，语文无要求\n  - VPD：\n    德语全称：Vorprüfungsdokumentation\n    中文名称：德国大学入学资格预审核证明\n    由 Uni-Assist（德国高校国际合作申请服务中心）出具，用于提前审核非欧盟申请者的学历、成绩和学分是否符合德国大学的入学标准，并把成绩换算成德国计分体系。提前3–6个月向 uni-assist 提交材料，因为：uni-assist处理时间通常为 4–6周，高峰期可能更长；VPD有效期为 1年，但部分大学要求VPD必须在申请截止前不超过6个月内开具\n  - APS：\n    全称 德国驻华使馆文化处留德人员审核部（Akademische Prüfstelle，简称 APS）审核中国学生的学历、成绩单、学位证等材料是否真实有效。\n  - 命题小论文：科学论文/论文应长约1000字，并且必须用英语书写\n\n\n\n> 总而言之：需要托福GRE过关，如果能在第一轮能力评估中通过（学科契合度以及GPA）就会直接录取，否则就要经过面试和考试。\n","source":"_posts/TMU硕士申请调研.md","raw":"---\ntitle: TMU硕士申请调研\ndate: 2025-07-17 20:37:37\ncategories: \n  - 随笔\ntags: \n  - 留学申请\n---\n### 资料来源\n\n本文所有资料均来自于TMU官网中[School of Computation,Information and Technology板块](https://www.cit.tum.de/en/cit/home/)，以下简称CIT学院。\n其中具体信息主要来自于其中的[学位项目板块](https://www.cit.tum.de/en/cit/studies/degree-programs/)\n\n### 硕士学制\n\n标准学制2年，以课程为主\n\n### 在当地工作\n\n毕业后到慕尼黑外国人事务局（KVR）把原来的学生居留直接换成“18 个月求职居留”（§ 16b Abs. 4 AufenthG）。\n在这 18 个月内可以无限制打工（不限天数、不限行业），以维持生活并积累相关经验\n找到与学位匹配的“合格工作”后，可立即把求职居留转换成“就业居留”（§ 18b AufenthG）。\n只要这份工作持续 24 个月、并缴纳社保，且德语达到 A1，就能申请德国永久居留。[pdf说明文件](https://www.community.tum.de/wp-content/uploads/2023/04/TU_Flyer_WorkingInGermany2023_WEB.pdf)\n\n总的而言，德国还是有一定IT缺口的。\n\n# CIT本科专业\n\n信息来自于[学位项目板块](https://www.cit.tum.de/en/cit/studies/degree-programs/)\n\n### 本科信息学（Informatics）培养方案（用于检查课程匹配度）\n\n[课程网址](https://www.cit.tum.de/cit/studium/studiengaenge/bachelor-informatik/studienplan/)\n本科培养方案要求翻译如下：\n{% asset_img \"课程.png\"%}\n对个人而言，这个专业是最契合国内本科计算机科学专业培养方案的。\n\n### 本科信息工程（Information Engineering）培养方案\n\n[官网文件](https://www.cit.tum.de/fileadmin/w00byx/cit/Studium/Studiengaenge/Bachelor_Information_Engineering_Heilbronn/20221213_Studiengangsdokumentation_BSc_IE_Teil_A_AbgabeSenat__1_.pdf)\n主要内容翻译如下：\n\n| 类别                                                   | 学分  | 说明                                           |\n| ------------------------------------------------------ | ----- | ---------------------------------------------- |\n| **必修：计算机科学**                             | 90 CP | 信息学核心课程                                 |\n| **必修：数学**                                   | 36 CP | 离散结构、线性代数、微积分、概率论             |\n| **选修：计算机科学**                             | 12 CP | 从实时系统、虚拟机、密码学等模块中选 2 门      |\n| **选修：经济/管理**                              | 18 CP | 财务会计、管理科学、物流与生产等 3 门          |\n| **选修：跨学科/软技能**                          | 9 CP  | 伦理、创业、跨文化沟通等                       |\n| **毕业论文 + 答辩**                              | 15 CP | 第 6 学期完成（12 CP 论文 + 3 CP 答辩）        |\n| **必修实践项目**                                 | 10 CP | 第 5 学期小组项目（Bachelor Practical Course） |\n| **必修研讨课**                                   | 5 CP  | 第 3 学期独立完成科研小课题                    |\n| 添加了一些经管类课程，其他本科专业大同小异，不再赘述。 |       |                                                |\n\n# CIT硕士专业  \n全部信息来自于[学位项目板块](https://www.cit.tum.de/en/cit/studies/degree-programs/)\n\n### 信息学(Informatics)硕士专业\n- [主页](https://www.cit.tum.de/en/cit/studies/degree-programs/master-informatics/)\n- 语言：英语\n- 申请期限\n  - 冬季学期：2月1日至5月31日\n  - 夏季学期：9月1日至11月30日\n- 申请流程[参考](https://www.tum.de/en/studies/application/master/application-master)\n  - [注册](https://campus.tum.de/tumonline/)\n  - 能力评估\n    - 在初始阶段，您在学士学位课程中获得的成绩以及您的书面文件将使用积分系统进行评估。根据累积的积分数量，申请人要么立即被录取，要么被拒绝，要么被邀请参加该部门进行的20分钟的招生面试。在某些情况下，对国际学生进行电话面试。\n    - 面试代表了程序的第二阶段，有助于确定申请人是否能够成功完成所需的学习课程。您可以在您期望的学位课程的学术和考试条例的附录2中找到更多信息。\n  - GRE分数要求：\n    Applicants with a Degree from Bangladesh, China, India, Iran or Pakistan have to submit a GRE (General) Test. We have defined required minimum scores, lower scores will not be accepted!\n    The required scores are:\n    Verbal reasoning: (will not be taken into account anymore)\n    Quantitative reasoning: 164\n    Analytical writing: 4.0  \n    即：数学要求164，写作要求4.0，语文无要求\n  - VPD：\n    德语全称：Vorprüfungsdokumentation\n    中文名称：德国大学入学资格预审核证明\n    由 Uni-Assist（德国高校国际合作申请服务中心）出具，用于提前审核非欧盟申请者的学历、成绩和学分是否符合德国大学的入学标准，并把成绩换算成德国计分体系。提前3–6个月向 uni-assist 提交材料，因为：uni-assist处理时间通常为 4–6周，高峰期可能更长；VPD有效期为 1年，但部分大学要求VPD必须在申请截止前不超过6个月内开具\n  - APS：\n    全称 德国驻华使馆文化处留德人员审核部（Akademische Prüfstelle，简称 APS）审核中国学生的学历、成绩单、学位证等材料是否真实有效。\n  - 命题小论文：科学论文/论文应长约1000字，并且必须用英语书写\n\n\n\n> 总而言之：需要托福GRE过关，如果能在第一轮能力评估中通过（学科契合度以及GPA）就会直接录取，否则就要经过面试和考试。\n","slug":"TMU硕士申请调研","published":1,"updated":"2025-10-11T10:00:58.041Z","_id":"cmf9mvzss0001ad9l6adhdu5p","comments":1,"layout":"post","photos":[],"content":"<h3 id=\"资料来源\"><a href=\"#资料来源\" class=\"headerlink\" title=\"资料来源\"></a>资料来源</h3><p>本文所有资料均来自于TMU官网中<a href=\"https://www.cit.tum.de/en/cit/home/\">School of Computation,Information and Technology板块</a>，以下简称CIT学院。<br>其中具体信息主要来自于其中的<a href=\"https://www.cit.tum.de/en/cit/studies/degree-programs/\">学位项目板块</a></p>\n<h3 id=\"硕士学制\"><a href=\"#硕士学制\" class=\"headerlink\" title=\"硕士学制\"></a>硕士学制</h3><p>标准学制2年，以课程为主</p>\n<h3 id=\"在当地工作\"><a href=\"#在当地工作\" class=\"headerlink\" title=\"在当地工作\"></a>在当地工作</h3><p>毕业后到慕尼黑外国人事务局（KVR）把原来的学生居留直接换成“18 个月求职居留”（§ 16b Abs. 4 AufenthG）。<br>在这 18 个月内可以无限制打工（不限天数、不限行业），以维持生活并积累相关经验<br>找到与学位匹配的“合格工作”后，可立即把求职居留转换成“就业居留”（§ 18b AufenthG）。<br>只要这份工作持续 24 个月、并缴纳社保，且德语达到 A1，就能申请德国永久居留。<a href=\"https://www.community.tum.de/wp-content/uploads/2023/04/TU_Flyer_WorkingInGermany2023_WEB.pdf\">pdf说明文件</a></p>\n<p>总的而言，德国还是有一定IT缺口的。</p>\n<h1 id=\"CIT本科专业\"><a href=\"#CIT本科专业\" class=\"headerlink\" title=\"CIT本科专业\"></a>CIT本科专业</h1><p>信息来自于<a href=\"https://www.cit.tum.de/en/cit/studies/degree-programs/\">学位项目板块</a></p>\n<h3 id=\"本科信息学（Informatics）培养方案（用于检查课程匹配度）\"><a href=\"#本科信息学（Informatics）培养方案（用于检查课程匹配度）\" class=\"headerlink\" title=\"本科信息学（Informatics）培养方案（用于检查课程匹配度）\"></a>本科信息学（Informatics）培养方案（用于检查课程匹配度）</h3><p><a href=\"https://www.cit.tum.de/cit/studium/studiengaenge/bachelor-informatik/studienplan/\">课程网址</a><br>本科培养方案要求翻译如下：</p>\n<img src=\"/2025/07/17/TMU%E7%A1%95%E5%A3%AB%E7%94%B3%E8%AF%B7%E8%B0%83%E7%A0%94/%E8%AF%BE%E7%A8%8B.png\" class=\"\">\n<p>对个人而言，这个专业是最契合国内本科计算机科学专业培养方案的。</p>\n<h3 id=\"本科信息工程（Information-Engineering）培养方案\"><a href=\"#本科信息工程（Information-Engineering）培养方案\" class=\"headerlink\" title=\"本科信息工程（Information Engineering）培养方案\"></a>本科信息工程（Information Engineering）培养方案</h3><p><a href=\"https://www.cit.tum.de/fileadmin/w00byx/cit/Studium/Studiengaenge/Bachelor_Information_Engineering_Heilbronn/20221213_Studiengangsdokumentation_BSc_IE_Teil_A_AbgabeSenat__1_.pdf\">官网文件</a><br>主要内容翻译如下：</p>\n<table>\n<thead>\n<tr>\n<th>类别</th>\n<th>学分</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>必修：计算机科学</strong></td>\n<td>90 CP</td>\n<td>信息学核心课程</td>\n</tr>\n<tr>\n<td><strong>必修：数学</strong></td>\n<td>36 CP</td>\n<td>离散结构、线性代数、微积分、概率论</td>\n</tr>\n<tr>\n<td><strong>选修：计算机科学</strong></td>\n<td>12 CP</td>\n<td>从实时系统、虚拟机、密码学等模块中选 2 门</td>\n</tr>\n<tr>\n<td><strong>选修：经济&#x2F;管理</strong></td>\n<td>18 CP</td>\n<td>财务会计、管理科学、物流与生产等 3 门</td>\n</tr>\n<tr>\n<td><strong>选修：跨学科&#x2F;软技能</strong></td>\n<td>9 CP</td>\n<td>伦理、创业、跨文化沟通等</td>\n</tr>\n<tr>\n<td><strong>毕业论文 + 答辩</strong></td>\n<td>15 CP</td>\n<td>第 6 学期完成（12 CP 论文 + 3 CP 答辩）</td>\n</tr>\n<tr>\n<td><strong>必修实践项目</strong></td>\n<td>10 CP</td>\n<td>第 5 学期小组项目（Bachelor Practical Course）</td>\n</tr>\n<tr>\n<td><strong>必修研讨课</strong></td>\n<td>5 CP</td>\n<td>第 3 学期独立完成科研小课题</td>\n</tr>\n<tr>\n<td>添加了一些经管类课程，其他本科专业大同小异，不再赘述。</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<h1 id=\"CIT硕士专业\"><a href=\"#CIT硕士专业\" class=\"headerlink\" title=\"CIT硕士专业\"></a>CIT硕士专业</h1><p>全部信息来自于<a href=\"https://www.cit.tum.de/en/cit/studies/degree-programs/\">学位项目板块</a></p>\n<h3 id=\"信息学-Informatics-硕士专业\"><a href=\"#信息学-Informatics-硕士专业\" class=\"headerlink\" title=\"信息学(Informatics)硕士专业\"></a>信息学(Informatics)硕士专业</h3><ul>\n<li><a href=\"https://www.cit.tum.de/en/cit/studies/degree-programs/master-informatics/\">主页</a></li>\n<li>语言：英语</li>\n<li>申请期限<ul>\n<li>冬季学期：2月1日至5月31日</li>\n<li>夏季学期：9月1日至11月30日</li>\n</ul>\n</li>\n<li>申请流程<a href=\"https://www.tum.de/en/studies/application/master/application-master\">参考</a><ul>\n<li><a href=\"https://campus.tum.de/tumonline/\">注册</a></li>\n<li>能力评估<ul>\n<li>在初始阶段，您在学士学位课程中获得的成绩以及您的书面文件将使用积分系统进行评估。根据累积的积分数量，申请人要么立即被录取，要么被拒绝，要么被邀请参加该部门进行的20分钟的招生面试。在某些情况下，对国际学生进行电话面试。</li>\n<li>面试代表了程序的第二阶段，有助于确定申请人是否能够成功完成所需的学习课程。您可以在您期望的学位课程的学术和考试条例的附录2中找到更多信息。</li>\n</ul>\n</li>\n<li>GRE分数要求：<br>Applicants with a Degree from Bangladesh, China, India, Iran or Pakistan have to submit a GRE (General) Test. We have defined required minimum scores, lower scores will not be accepted!<br>The required scores are:<br>Verbal reasoning: (will not be taken into account anymore)<br>Quantitative reasoning: 164<br>Analytical writing: 4.0<br>即：数学要求164，写作要求4.0，语文无要求</li>\n<li>VPD：<br>德语全称：Vorprüfungsdokumentation<br>中文名称：德国大学入学资格预审核证明<br>由 Uni-Assist（德国高校国际合作申请服务中心）出具，用于提前审核非欧盟申请者的学历、成绩和学分是否符合德国大学的入学标准，并把成绩换算成德国计分体系。提前3–6个月向 uni-assist 提交材料，因为：uni-assist处理时间通常为 4–6周，高峰期可能更长；VPD有效期为 1年，但部分大学要求VPD必须在申请截止前不超过6个月内开具</li>\n<li>APS：<br>全称 德国驻华使馆文化处留德人员审核部（Akademische Prüfstelle，简称 APS）审核中国学生的学历、成绩单、学位证等材料是否真实有效。</li>\n<li>命题小论文：科学论文&#x2F;论文应长约1000字，并且必须用英语书写</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>总而言之：需要托福GRE过关，如果能在第一轮能力评估中通过（学科契合度以及GPA）就会直接录取，否则就要经过面试和考试。</p>\n</blockquote>\n","excerpt":"","more":"<h3 id=\"资料来源\"><a href=\"#资料来源\" class=\"headerlink\" title=\"资料来源\"></a>资料来源</h3><p>本文所有资料均来自于TMU官网中<a href=\"https://www.cit.tum.de/en/cit/home/\">School of Computation,Information and Technology板块</a>，以下简称CIT学院。<br>其中具体信息主要来自于其中的<a href=\"https://www.cit.tum.de/en/cit/studies/degree-programs/\">学位项目板块</a></p>\n<h3 id=\"硕士学制\"><a href=\"#硕士学制\" class=\"headerlink\" title=\"硕士学制\"></a>硕士学制</h3><p>标准学制2年，以课程为主</p>\n<h3 id=\"在当地工作\"><a href=\"#在当地工作\" class=\"headerlink\" title=\"在当地工作\"></a>在当地工作</h3><p>毕业后到慕尼黑外国人事务局（KVR）把原来的学生居留直接换成“18 个月求职居留”（§ 16b Abs. 4 AufenthG）。<br>在这 18 个月内可以无限制打工（不限天数、不限行业），以维持生活并积累相关经验<br>找到与学位匹配的“合格工作”后，可立即把求职居留转换成“就业居留”（§ 18b AufenthG）。<br>只要这份工作持续 24 个月、并缴纳社保，且德语达到 A1，就能申请德国永久居留。<a href=\"https://www.community.tum.de/wp-content/uploads/2023/04/TU_Flyer_WorkingInGermany2023_WEB.pdf\">pdf说明文件</a></p>\n<p>总的而言，德国还是有一定IT缺口的。</p>\n<h1 id=\"CIT本科专业\"><a href=\"#CIT本科专业\" class=\"headerlink\" title=\"CIT本科专业\"></a>CIT本科专业</h1><p>信息来自于<a href=\"https://www.cit.tum.de/en/cit/studies/degree-programs/\">学位项目板块</a></p>\n<h3 id=\"本科信息学（Informatics）培养方案（用于检查课程匹配度）\"><a href=\"#本科信息学（Informatics）培养方案（用于检查课程匹配度）\" class=\"headerlink\" title=\"本科信息学（Informatics）培养方案（用于检查课程匹配度）\"></a>本科信息学（Informatics）培养方案（用于检查课程匹配度）</h3><p><a href=\"https://www.cit.tum.de/cit/studium/studiengaenge/bachelor-informatik/studienplan/\">课程网址</a><br>本科培养方案要求翻译如下：</p>\n<img src=\"/2025/07/17/TMU%E7%A1%95%E5%A3%AB%E7%94%B3%E8%AF%B7%E8%B0%83%E7%A0%94/%E8%AF%BE%E7%A8%8B.png\" class=\"\">\n<p>对个人而言，这个专业是最契合国内本科计算机科学专业培养方案的。</p>\n<h3 id=\"本科信息工程（Information-Engineering）培养方案\"><a href=\"#本科信息工程（Information-Engineering）培养方案\" class=\"headerlink\" title=\"本科信息工程（Information Engineering）培养方案\"></a>本科信息工程（Information Engineering）培养方案</h3><p><a href=\"https://www.cit.tum.de/fileadmin/w00byx/cit/Studium/Studiengaenge/Bachelor_Information_Engineering_Heilbronn/20221213_Studiengangsdokumentation_BSc_IE_Teil_A_AbgabeSenat__1_.pdf\">官网文件</a><br>主要内容翻译如下：</p>\n<table>\n<thead>\n<tr>\n<th>类别</th>\n<th>学分</th>\n<th>说明</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><strong>必修：计算机科学</strong></td>\n<td>90 CP</td>\n<td>信息学核心课程</td>\n</tr>\n<tr>\n<td><strong>必修：数学</strong></td>\n<td>36 CP</td>\n<td>离散结构、线性代数、微积分、概率论</td>\n</tr>\n<tr>\n<td><strong>选修：计算机科学</strong></td>\n<td>12 CP</td>\n<td>从实时系统、虚拟机、密码学等模块中选 2 门</td>\n</tr>\n<tr>\n<td><strong>选修：经济&#x2F;管理</strong></td>\n<td>18 CP</td>\n<td>财务会计、管理科学、物流与生产等 3 门</td>\n</tr>\n<tr>\n<td><strong>选修：跨学科&#x2F;软技能</strong></td>\n<td>9 CP</td>\n<td>伦理、创业、跨文化沟通等</td>\n</tr>\n<tr>\n<td><strong>毕业论文 + 答辩</strong></td>\n<td>15 CP</td>\n<td>第 6 学期完成（12 CP 论文 + 3 CP 答辩）</td>\n</tr>\n<tr>\n<td><strong>必修实践项目</strong></td>\n<td>10 CP</td>\n<td>第 5 学期小组项目（Bachelor Practical Course）</td>\n</tr>\n<tr>\n<td><strong>必修研讨课</strong></td>\n<td>5 CP</td>\n<td>第 3 学期独立完成科研小课题</td>\n</tr>\n<tr>\n<td>添加了一些经管类课程，其他本科专业大同小异，不再赘述。</td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<h1 id=\"CIT硕士专业\"><a href=\"#CIT硕士专业\" class=\"headerlink\" title=\"CIT硕士专业\"></a>CIT硕士专业</h1><p>全部信息来自于<a href=\"https://www.cit.tum.de/en/cit/studies/degree-programs/\">学位项目板块</a></p>\n<h3 id=\"信息学-Informatics-硕士专业\"><a href=\"#信息学-Informatics-硕士专业\" class=\"headerlink\" title=\"信息学(Informatics)硕士专业\"></a>信息学(Informatics)硕士专业</h3><ul>\n<li><a href=\"https://www.cit.tum.de/en/cit/studies/degree-programs/master-informatics/\">主页</a></li>\n<li>语言：英语</li>\n<li>申请期限<ul>\n<li>冬季学期：2月1日至5月31日</li>\n<li>夏季学期：9月1日至11月30日</li>\n</ul>\n</li>\n<li>申请流程<a href=\"https://www.tum.de/en/studies/application/master/application-master\">参考</a><ul>\n<li><a href=\"https://campus.tum.de/tumonline/\">注册</a></li>\n<li>能力评估<ul>\n<li>在初始阶段，您在学士学位课程中获得的成绩以及您的书面文件将使用积分系统进行评估。根据累积的积分数量，申请人要么立即被录取，要么被拒绝，要么被邀请参加该部门进行的20分钟的招生面试。在某些情况下，对国际学生进行电话面试。</li>\n<li>面试代表了程序的第二阶段，有助于确定申请人是否能够成功完成所需的学习课程。您可以在您期望的学位课程的学术和考试条例的附录2中找到更多信息。</li>\n</ul>\n</li>\n<li>GRE分数要求：<br>Applicants with a Degree from Bangladesh, China, India, Iran or Pakistan have to submit a GRE (General) Test. We have defined required minimum scores, lower scores will not be accepted!<br>The required scores are:<br>Verbal reasoning: (will not be taken into account anymore)<br>Quantitative reasoning: 164<br>Analytical writing: 4.0<br>即：数学要求164，写作要求4.0，语文无要求</li>\n<li>VPD：<br>德语全称：Vorprüfungsdokumentation<br>中文名称：德国大学入学资格预审核证明<br>由 Uni-Assist（德国高校国际合作申请服务中心）出具，用于提前审核非欧盟申请者的学历、成绩和学分是否符合德国大学的入学标准，并把成绩换算成德国计分体系。提前3–6个月向 uni-assist 提交材料，因为：uni-assist处理时间通常为 4–6周，高峰期可能更长；VPD有效期为 1年，但部分大学要求VPD必须在申请截止前不超过6个月内开具</li>\n<li>APS：<br>全称 德国驻华使馆文化处留德人员审核部（Akademische Prüfstelle，简称 APS）审核中国学生的学历、成绩单、学位证等材料是否真实有效。</li>\n<li>命题小论文：科学论文&#x2F;论文应长约1000字，并且必须用英语书写</li>\n</ul>\n</li>\n</ul>\n<blockquote>\n<p>总而言之：需要托福GRE过关，如果能在第一轮能力评估中通过（学科契合度以及GPA）就会直接录取，否则就要经过面试和考试。</p>\n</blockquote>\n"},{"title":"TUDelt硕士申请调研","date":"2025-08-07T03:06:38.000Z","_content":"### 资料来源\n\nhttps://www.tudelft.nl/en/education/programmes/masters\n\n### 硕士学制\n\n两年\n学费：20,000欧元/年（约16.64万人民币/年）\n\n### 在当地工作\n\n毕业后可申请为期一年的求职签证.\n在求职签证的一年之内，如果顺利找到工作，就可以让雇主帮你申请荷兰工作签证\n欧盟永居申请：在荷兰连续居住超过5年\n\n## MSc Computer & Embedded Systems Engineering\n\nhttps://www.tudelft.nl/en/education/programmes/masters/msc-computer-embedded-systems-engineering\n\n#### 课程匹配：\n\n招生委员会将根据以下关键科目的学习成绩和学习量对申请进行评估：\n数学（微积分、线性代数、数值分析、微分方程）\n概率和统计\n计算机架构\n编程（尤其是C语言）\n\n也非常相关的是：\n数字系统（包括硬件描述语言）\n信号和系统\n信号处理\n操作系统\n\n#### 语言要求：\n\n我们没有设定最低GRE分数，但我们寻找语言推理最低分为154分、定量推理最低分为163分和分析性写作最低分为4.0分的申请人。我们保留拒绝没有这些分数的申请人的权利。\n托福最好100分以上\n\n#### 申请流程\n\n只能申请一个硕士项目\n10月15日开始接收申请\n申请截止日期为1月15日\n\n## MSc Data Science and Artificial Intelligence Technology\n\n#### 课程要求：\n\n申请将由招生委员会根据关键科目的学习成绩和学习负荷进行评估。计算机科学科目的最低学习要求为120个ECTS，其中至少100个ECTS在以下关键科目中获得：\n\n数学和建模：\n微积分、线性代数、概率论和统计学——至少15个ECTS\n软件开发基础知识：\n面向对象编程，软件质量和测试，软件工程方法，编程语言概念，面向对象编程项目，软件项目——至少30个ECTS\n计算机系统：\n计算机组织，计算机网络——至少10个ECTS\n基础计算机科学：\n逻辑、算法和数据结构、算法设计、可计算性——至少15个ECTS\n数据和信息系统：\n机器学习、数据管理、网络和数据库技术——至少15个ECTS\n","source":"_posts/TUDelt硕士申请调研.md","raw":"---\ntitle: TUDelt硕士申请调研\ndate: 2025-08-07 11:06:38\ncategories: \n  - 随笔\ntags: \n  - 留学申请\n---\n### 资料来源\n\nhttps://www.tudelft.nl/en/education/programmes/masters\n\n### 硕士学制\n\n两年\n学费：20,000欧元/年（约16.64万人民币/年）\n\n### 在当地工作\n\n毕业后可申请为期一年的求职签证.\n在求职签证的一年之内，如果顺利找到工作，就可以让雇主帮你申请荷兰工作签证\n欧盟永居申请：在荷兰连续居住超过5年\n\n## MSc Computer & Embedded Systems Engineering\n\nhttps://www.tudelft.nl/en/education/programmes/masters/msc-computer-embedded-systems-engineering\n\n#### 课程匹配：\n\n招生委员会将根据以下关键科目的学习成绩和学习量对申请进行评估：\n数学（微积分、线性代数、数值分析、微分方程）\n概率和统计\n计算机架构\n编程（尤其是C语言）\n\n也非常相关的是：\n数字系统（包括硬件描述语言）\n信号和系统\n信号处理\n操作系统\n\n#### 语言要求：\n\n我们没有设定最低GRE分数，但我们寻找语言推理最低分为154分、定量推理最低分为163分和分析性写作最低分为4.0分的申请人。我们保留拒绝没有这些分数的申请人的权利。\n托福最好100分以上\n\n#### 申请流程\n\n只能申请一个硕士项目\n10月15日开始接收申请\n申请截止日期为1月15日\n\n## MSc Data Science and Artificial Intelligence Technology\n\n#### 课程要求：\n\n申请将由招生委员会根据关键科目的学习成绩和学习负荷进行评估。计算机科学科目的最低学习要求为120个ECTS，其中至少100个ECTS在以下关键科目中获得：\n\n数学和建模：\n微积分、线性代数、概率论和统计学——至少15个ECTS\n软件开发基础知识：\n面向对象编程，软件质量和测试，软件工程方法，编程语言概念，面向对象编程项目，软件项目——至少30个ECTS\n计算机系统：\n计算机组织，计算机网络——至少10个ECTS\n基础计算机科学：\n逻辑、算法和数据结构、算法设计、可计算性——至少15个ECTS\n数据和信息系统：\n机器学习、数据管理、网络和数据库技术——至少15个ECTS\n","slug":"TUDelt硕士申请调研","published":1,"updated":"2025-10-11T09:51:27.952Z","_id":"cmf9mvzst0002ad9l90ufhg6v","comments":1,"layout":"post","photos":[],"content":"<h3 id=\"资料来源\"><a href=\"#资料来源\" class=\"headerlink\" title=\"资料来源\"></a>资料来源</h3><p><a href=\"https://www.tudelft.nl/en/education/programmes/masters\">https://www.tudelft.nl/en/education/programmes/masters</a></p>\n<h3 id=\"硕士学制\"><a href=\"#硕士学制\" class=\"headerlink\" title=\"硕士学制\"></a>硕士学制</h3><p>两年<br>学费：20,000欧元&#x2F;年（约16.64万人民币&#x2F;年）</p>\n<h3 id=\"在当地工作\"><a href=\"#在当地工作\" class=\"headerlink\" title=\"在当地工作\"></a>在当地工作</h3><p>毕业后可申请为期一年的求职签证.<br>在求职签证的一年之内，如果顺利找到工作，就可以让雇主帮你申请荷兰工作签证<br>欧盟永居申请：在荷兰连续居住超过5年</p>\n<h2 id=\"MSc-Computer-Embedded-Systems-Engineering\"><a href=\"#MSc-Computer-Embedded-Systems-Engineering\" class=\"headerlink\" title=\"MSc Computer &amp; Embedded Systems Engineering\"></a>MSc Computer &amp; Embedded Systems Engineering</h2><p><a href=\"https://www.tudelft.nl/en/education/programmes/masters/msc-computer-embedded-systems-engineering\">https://www.tudelft.nl/en/education/programmes/masters/msc-computer-embedded-systems-engineering</a></p>\n<h4 id=\"课程匹配：\"><a href=\"#课程匹配：\" class=\"headerlink\" title=\"课程匹配：\"></a>课程匹配：</h4><p>招生委员会将根据以下关键科目的学习成绩和学习量对申请进行评估：<br>数学（微积分、线性代数、数值分析、微分方程）<br>概率和统计<br>计算机架构<br>编程（尤其是C语言）</p>\n<p>也非常相关的是：<br>数字系统（包括硬件描述语言）<br>信号和系统<br>信号处理<br>操作系统</p>\n<h4 id=\"语言要求：\"><a href=\"#语言要求：\" class=\"headerlink\" title=\"语言要求：\"></a>语言要求：</h4><p>我们没有设定最低GRE分数，但我们寻找语言推理最低分为154分、定量推理最低分为163分和分析性写作最低分为4.0分的申请人。我们保留拒绝没有这些分数的申请人的权利。<br>托福最好100分以上</p>\n<h4 id=\"申请流程\"><a href=\"#申请流程\" class=\"headerlink\" title=\"申请流程\"></a>申请流程</h4><p>只能申请一个硕士项目<br>10月15日开始接收申请<br>申请截止日期为1月15日</p>\n<h2 id=\"MSc-Data-Science-and-Artificial-Intelligence-Technology\"><a href=\"#MSc-Data-Science-and-Artificial-Intelligence-Technology\" class=\"headerlink\" title=\"MSc Data Science and Artificial Intelligence Technology\"></a>MSc Data Science and Artificial Intelligence Technology</h2><h4 id=\"课程要求：\"><a href=\"#课程要求：\" class=\"headerlink\" title=\"课程要求：\"></a>课程要求：</h4><p>申请将由招生委员会根据关键科目的学习成绩和学习负荷进行评估。计算机科学科目的最低学习要求为120个ECTS，其中至少100个ECTS在以下关键科目中获得：</p>\n<p>数学和建模：<br>微积分、线性代数、概率论和统计学——至少15个ECTS<br>软件开发基础知识：<br>面向对象编程，软件质量和测试，软件工程方法，编程语言概念，面向对象编程项目，软件项目——至少30个ECTS<br>计算机系统：<br>计算机组织，计算机网络——至少10个ECTS<br>基础计算机科学：<br>逻辑、算法和数据结构、算法设计、可计算性——至少15个ECTS<br>数据和信息系统：<br>机器学习、数据管理、网络和数据库技术——至少15个ECTS</p>\n","excerpt":"","more":"<h3 id=\"资料来源\"><a href=\"#资料来源\" class=\"headerlink\" title=\"资料来源\"></a>资料来源</h3><p><a href=\"https://www.tudelft.nl/en/education/programmes/masters\">https://www.tudelft.nl/en/education/programmes/masters</a></p>\n<h3 id=\"硕士学制\"><a href=\"#硕士学制\" class=\"headerlink\" title=\"硕士学制\"></a>硕士学制</h3><p>两年<br>学费：20,000欧元&#x2F;年（约16.64万人民币&#x2F;年）</p>\n<h3 id=\"在当地工作\"><a href=\"#在当地工作\" class=\"headerlink\" title=\"在当地工作\"></a>在当地工作</h3><p>毕业后可申请为期一年的求职签证.<br>在求职签证的一年之内，如果顺利找到工作，就可以让雇主帮你申请荷兰工作签证<br>欧盟永居申请：在荷兰连续居住超过5年</p>\n<h2 id=\"MSc-Computer-Embedded-Systems-Engineering\"><a href=\"#MSc-Computer-Embedded-Systems-Engineering\" class=\"headerlink\" title=\"MSc Computer &amp; Embedded Systems Engineering\"></a>MSc Computer &amp; Embedded Systems Engineering</h2><p><a href=\"https://www.tudelft.nl/en/education/programmes/masters/msc-computer-embedded-systems-engineering\">https://www.tudelft.nl/en/education/programmes/masters/msc-computer-embedded-systems-engineering</a></p>\n<h4 id=\"课程匹配：\"><a href=\"#课程匹配：\" class=\"headerlink\" title=\"课程匹配：\"></a>课程匹配：</h4><p>招生委员会将根据以下关键科目的学习成绩和学习量对申请进行评估：<br>数学（微积分、线性代数、数值分析、微分方程）<br>概率和统计<br>计算机架构<br>编程（尤其是C语言）</p>\n<p>也非常相关的是：<br>数字系统（包括硬件描述语言）<br>信号和系统<br>信号处理<br>操作系统</p>\n<h4 id=\"语言要求：\"><a href=\"#语言要求：\" class=\"headerlink\" title=\"语言要求：\"></a>语言要求：</h4><p>我们没有设定最低GRE分数，但我们寻找语言推理最低分为154分、定量推理最低分为163分和分析性写作最低分为4.0分的申请人。我们保留拒绝没有这些分数的申请人的权利。<br>托福最好100分以上</p>\n<h4 id=\"申请流程\"><a href=\"#申请流程\" class=\"headerlink\" title=\"申请流程\"></a>申请流程</h4><p>只能申请一个硕士项目<br>10月15日开始接收申请<br>申请截止日期为1月15日</p>\n<h2 id=\"MSc-Data-Science-and-Artificial-Intelligence-Technology\"><a href=\"#MSc-Data-Science-and-Artificial-Intelligence-Technology\" class=\"headerlink\" title=\"MSc Data Science and Artificial Intelligence Technology\"></a>MSc Data Science and Artificial Intelligence Technology</h2><h4 id=\"课程要求：\"><a href=\"#课程要求：\" class=\"headerlink\" title=\"课程要求：\"></a>课程要求：</h4><p>申请将由招生委员会根据关键科目的学习成绩和学习负荷进行评估。计算机科学科目的最低学习要求为120个ECTS，其中至少100个ECTS在以下关键科目中获得：</p>\n<p>数学和建模：<br>微积分、线性代数、概率论和统计学——至少15个ECTS<br>软件开发基础知识：<br>面向对象编程，软件质量和测试，软件工程方法，编程语言概念，面向对象编程项目，软件项目——至少30个ECTS<br>计算机系统：<br>计算机组织，计算机网络——至少10个ECTS<br>基础计算机科学：<br>逻辑、算法和数据结构、算法设计、可计算性——至少15个ECTS<br>数据和信息系统：<br>机器学习、数据管理、网络和数据库技术——至少15个ECTS</p>\n"},{"title":"torch的封装层次","date":"2025-07-12T08:21:40.000Z","_content":"> 作为初学者,这篇文章对我非常有帮助。如果直接看pytorch的组织结构[github](https://github.com/pytorch/pytorch)，总是一头雾水，这篇文章提供了一个帮助，去了解pytorch是怎样一步步组织起来的。\n\n> 0. cuda算子，一般是由核函数组成的.cu和.cpp文件\n> 1. cuda封装，提供参数，调用算子，不进行存储\n> 2. autograd算子，存储求导所需要的临时变量\n> 3. function封装，在上一层的基础上做一些健壮性工作\n> 4. Module封装，把函数封装成类，为的是实现永久性存储\n\ntorch中同一个功能，不同层级的封装有什么用？我应该用什么层级的封装？\n-------------------------------------------------------------------\n\n1:首先我们说在torch中你能看到的最基础封装是cuda封装，或者叫[cuda算子](https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=cuda%E7%AE%97%E5%AD%90&zhida_source=entity)，我们算它是1级封装。（方便起见我们这里忽略triton等其他方式实现的算子）\n\n这个封装层级下你可能会看到这样的调用方式：\n\n```text\nGEMM_cuda.fwd(mat1,mat2)\nGEMM_cuda.bwd(grad_o,mat1,mat2)\n```\n\n这种封装是python封装的最底层，它是在调用更底层的c++算子，实现矩阵运算的正向传播和反向传播。\n\nc++这个层级的算子只负责计算，计算之后相应的内存空间就销毁，不会存储任何东西。\n\n但我们知道torch是支持自动求导的，自动求导是依据链式法则实现的。一个简单的乘法：y=wx，计算w的导数：dy/dw = x，你会发现w的导数就是x，那么在我们计算w的导数时，就需要知道x，而x是正向传播时传递过来的，因此我们需要在正向传播时存下这个x。上面又说了cuda算子只负责计算，不负责存储，那么我们就需要更高一级的封装，来存储这些求导所使用的临时变量。\n\n---\n\n2: 在cuda算子之上的2级封装是[autograd算子](https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=autograd%E7%AE%97%E5%AD%90&zhida_source=entity)，它是通过继承torch.autograd.Function来实现的。这个层级的封装就是为了存储求导所需要的临时变量。从这一个层级开始就都是python代码了。\n\n你可能见到这种形式的autograd算子：\n\n```text\nimport torch\nclass TensorModelParallelCrossEntropy(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, logits, target, label_smoothing=0.0):\n        # do something\n        ctx.save_for_backward(...)\n        return loss\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        # do something\n        ... = ctx.saved_tensors\n        return grad_input, None, None\n```\n\n你可以看到这种算子中会存在一个save_for_backward函数，专门存储反向传播需要的临时变量。\n\n这种算子可以通过下面这种方式调用：\n\n```text\nce_loss = TensorModelParallelCrossEntropy.apply(logits,labels)\n```\n\n你可以看到调用这种算子并不是通过使用它的forward或者backward函数，而是使用apply函数。这里torch会进行一些封装，例如调用apply后，会用forward进行计算，并将backward添加到tensor的grad_fn属性计算图中，求导时自动调用。会在使用了torch.no_grad()上下文，不需要求导时，自动抛弃掉save_for_backward存储的张量。但是这种层级用的也不是太常见，首先观察forward函数的输入参数和backward的输出参数。backward函数返回的梯度数量必须和forward输入参数的数量相同，但是可以用None占位。比如target是标签，label_smoothing是超参，不可学习，不需要导数，这里就会用None占位。因此当你需要某一个功能的时候，需要严格的选择你需要的autograd算子，达到最佳的计算效率，不需要计算的东西不要算。\n\n---\n\n3: 接下来就是第3级function封装。function封装的作用就是增加autograd算子的灵活性和健壮性，比如做一些异常检测，默认值填补，找到合适的autograd算子分发等等，比如这样：\n\n```text\ndef linear_with_grad_accumulation_and_async_allreduce(input,weight,bias,lora_a=None,lora_b=None):\n  assert input.is_cuda() and weight.is_cuda()\n  if lora_a is not None and lora_b is not None:\n    return LoraLinearWithGradAccumulationAndAsyncCommunication.apply(input,weight,bias,lora_a,lora_b)\n  else:\n    return LinearWithGradAccumulationAndAsyncCommunication.apply(input,weight,bias)\n```\n\n[torch.nn](https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=torch.nn&zhida_source=entity).functional里面的函数就是这一级封装，这一级的函数对于大部分的人来说已经可以拿来用了，比如：\n\n```text\nfrom torch.nn.functional import linear,dropout\nlinear(input,weight,bias)\ndropout(input,p=0.1,training=True)\n```\n\n但是这个层级的封装依旧只会存储正、反向传播的临时变量，并不会存储一些持久化存在的变量。\n\n比如看到linear函数，它的输入有input、weight、bias，其中input是一个临时变量，你的模型输入数据了，input就有，不输入就没有，输入不同的值input也不同。但是weight和bias是模型定义的时候就存在的，与你是否正向传播无关，也不会随着你输入input的值不同而改变。看到dropout函数，丢弃率p和模型当前是处于训练状态还是推理状态，也不是一个会每次都变的值。所以我们还需要一层封装来存储这些不会临时改变的东西。\n\n---\n\n4:这第4级封装就是torch的Module级别封装，也就是题主题目中提到的“用类实现”。类似这个样子：\n\n```text\nclass Linear(torch.nn.Module):\n  \n    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n                 device=None, dtype=None) -> None:\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = torch.nn.Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n        if bias:\n            self.bias = torch.nn.Parameter(torch.empty(out_features, **factory_kwargs))\n        else:\n            self.register_parameter('bias', None)\n        self.reset_parameters()\n\n    def reset_parameters(self) -> None:\n        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.linear(input, self.weight, self.bias)\n```\n\n它会帮你定义持久存储的参数weight和bias，会帮你自动初始化这些参数，比如使用kaiming初始化。在你调用这个类创建的实例时，它会调用这个类的forward函数：\n\n```text\nlayer = Linear(10,5,bias=False)\nx = torch.randn(2,10)\ny = layer(x)\n```\n\n[Module封装](https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=Module%E5%B0%81%E8%A3%85&zhida_source=entity)和autograd封装一样，调用和定义的函数名是不同的，同样是因为torch后台帮你做了一些操作，比如判断类是否有某个属性，判断类多重继承时应该调用谁的函数，给正反向传播的输入和输出添加一些钩子函数等。\n\n到这里题主的问题，为什么要用类，为什么不用函数就已经很明确了。不想管理持久化的变量，就用Module封装，想要手动管理，就用function封装。想要自定义正反向传播的计算方法，就去写autograd算子，想炸裂提效，做算子融合，就去写cuda或者triton算子。\n\n> 作者：真中合欢\n> 链接：https://www.zhihu.com/question/677187311/answer/3780895706\n","source":"_posts/torch的封装层次.md","raw":"---\ntitle: torch的封装层次\ncategories:\n  - 转载\ntags:\n  - pytorch\ndate: 2025-07-12 16:21:40\n---\n> 作为初学者,这篇文章对我非常有帮助。如果直接看pytorch的组织结构[github](https://github.com/pytorch/pytorch)，总是一头雾水，这篇文章提供了一个帮助，去了解pytorch是怎样一步步组织起来的。\n\n> 0. cuda算子，一般是由核函数组成的.cu和.cpp文件\n> 1. cuda封装，提供参数，调用算子，不进行存储\n> 2. autograd算子，存储求导所需要的临时变量\n> 3. function封装，在上一层的基础上做一些健壮性工作\n> 4. Module封装，把函数封装成类，为的是实现永久性存储\n\ntorch中同一个功能，不同层级的封装有什么用？我应该用什么层级的封装？\n-------------------------------------------------------------------\n\n1:首先我们说在torch中你能看到的最基础封装是cuda封装，或者叫[cuda算子](https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=cuda%E7%AE%97%E5%AD%90&zhida_source=entity)，我们算它是1级封装。（方便起见我们这里忽略triton等其他方式实现的算子）\n\n这个封装层级下你可能会看到这样的调用方式：\n\n```text\nGEMM_cuda.fwd(mat1,mat2)\nGEMM_cuda.bwd(grad_o,mat1,mat2)\n```\n\n这种封装是python封装的最底层，它是在调用更底层的c++算子，实现矩阵运算的正向传播和反向传播。\n\nc++这个层级的算子只负责计算，计算之后相应的内存空间就销毁，不会存储任何东西。\n\n但我们知道torch是支持自动求导的，自动求导是依据链式法则实现的。一个简单的乘法：y=wx，计算w的导数：dy/dw = x，你会发现w的导数就是x，那么在我们计算w的导数时，就需要知道x，而x是正向传播时传递过来的，因此我们需要在正向传播时存下这个x。上面又说了cuda算子只负责计算，不负责存储，那么我们就需要更高一级的封装，来存储这些求导所使用的临时变量。\n\n---\n\n2: 在cuda算子之上的2级封装是[autograd算子](https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=autograd%E7%AE%97%E5%AD%90&zhida_source=entity)，它是通过继承torch.autograd.Function来实现的。这个层级的封装就是为了存储求导所需要的临时变量。从这一个层级开始就都是python代码了。\n\n你可能见到这种形式的autograd算子：\n\n```text\nimport torch\nclass TensorModelParallelCrossEntropy(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, logits, target, label_smoothing=0.0):\n        # do something\n        ctx.save_for_backward(...)\n        return loss\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        # do something\n        ... = ctx.saved_tensors\n        return grad_input, None, None\n```\n\n你可以看到这种算子中会存在一个save_for_backward函数，专门存储反向传播需要的临时变量。\n\n这种算子可以通过下面这种方式调用：\n\n```text\nce_loss = TensorModelParallelCrossEntropy.apply(logits,labels)\n```\n\n你可以看到调用这种算子并不是通过使用它的forward或者backward函数，而是使用apply函数。这里torch会进行一些封装，例如调用apply后，会用forward进行计算，并将backward添加到tensor的grad_fn属性计算图中，求导时自动调用。会在使用了torch.no_grad()上下文，不需要求导时，自动抛弃掉save_for_backward存储的张量。但是这种层级用的也不是太常见，首先观察forward函数的输入参数和backward的输出参数。backward函数返回的梯度数量必须和forward输入参数的数量相同，但是可以用None占位。比如target是标签，label_smoothing是超参，不可学习，不需要导数，这里就会用None占位。因此当你需要某一个功能的时候，需要严格的选择你需要的autograd算子，达到最佳的计算效率，不需要计算的东西不要算。\n\n---\n\n3: 接下来就是第3级function封装。function封装的作用就是增加autograd算子的灵活性和健壮性，比如做一些异常检测，默认值填补，找到合适的autograd算子分发等等，比如这样：\n\n```text\ndef linear_with_grad_accumulation_and_async_allreduce(input,weight,bias,lora_a=None,lora_b=None):\n  assert input.is_cuda() and weight.is_cuda()\n  if lora_a is not None and lora_b is not None:\n    return LoraLinearWithGradAccumulationAndAsyncCommunication.apply(input,weight,bias,lora_a,lora_b)\n  else:\n    return LinearWithGradAccumulationAndAsyncCommunication.apply(input,weight,bias)\n```\n\n[torch.nn](https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=torch.nn&zhida_source=entity).functional里面的函数就是这一级封装，这一级的函数对于大部分的人来说已经可以拿来用了，比如：\n\n```text\nfrom torch.nn.functional import linear,dropout\nlinear(input,weight,bias)\ndropout(input,p=0.1,training=True)\n```\n\n但是这个层级的封装依旧只会存储正、反向传播的临时变量，并不会存储一些持久化存在的变量。\n\n比如看到linear函数，它的输入有input、weight、bias，其中input是一个临时变量，你的模型输入数据了，input就有，不输入就没有，输入不同的值input也不同。但是weight和bias是模型定义的时候就存在的，与你是否正向传播无关，也不会随着你输入input的值不同而改变。看到dropout函数，丢弃率p和模型当前是处于训练状态还是推理状态，也不是一个会每次都变的值。所以我们还需要一层封装来存储这些不会临时改变的东西。\n\n---\n\n4:这第4级封装就是torch的Module级别封装，也就是题主题目中提到的“用类实现”。类似这个样子：\n\n```text\nclass Linear(torch.nn.Module):\n  \n    def __init__(self, in_features: int, out_features: int, bias: bool = True,\n                 device=None, dtype=None) -> None:\n        factory_kwargs = {'device': device, 'dtype': dtype}\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.weight = torch.nn.Parameter(torch.empty((out_features, in_features), **factory_kwargs))\n        if bias:\n            self.bias = torch.nn.Parameter(torch.empty(out_features, **factory_kwargs))\n        else:\n            self.register_parameter('bias', None)\n        self.reset_parameters()\n\n    def reset_parameters(self) -> None:\n        init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n        if self.bias is not None:\n            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)\n            bound = 1 / math.sqrt(fan_in) if fan_in > 0 else 0\n            init.uniform_(self.bias, -bound, bound)\n\n    def forward(self, input: Tensor) -> Tensor:\n        return F.linear(input, self.weight, self.bias)\n```\n\n它会帮你定义持久存储的参数weight和bias，会帮你自动初始化这些参数，比如使用kaiming初始化。在你调用这个类创建的实例时，它会调用这个类的forward函数：\n\n```text\nlayer = Linear(10,5,bias=False)\nx = torch.randn(2,10)\ny = layer(x)\n```\n\n[Module封装](https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=Module%E5%B0%81%E8%A3%85&zhida_source=entity)和autograd封装一样，调用和定义的函数名是不同的，同样是因为torch后台帮你做了一些操作，比如判断类是否有某个属性，判断类多重继承时应该调用谁的函数，给正反向传播的输入和输出添加一些钩子函数等。\n\n到这里题主的问题，为什么要用类，为什么不用函数就已经很明确了。不想管理持久化的变量，就用Module封装，想要手动管理，就用function封装。想要自定义正反向传播的计算方法，就去写autograd算子，想炸裂提效，做算子融合，就去写cuda或者triton算子。\n\n> 作者：真中合欢\n> 链接：https://www.zhihu.com/question/677187311/answer/3780895706\n","slug":"torch的封装层次","published":1,"updated":"2025-10-11T09:49:59.981Z","_id":"cmf9mvzsv0005ad9lbbo7d19c","comments":1,"layout":"post","photos":[],"content":"<blockquote>\n<p>作为初学者,这篇文章对我非常有帮助。如果直接看pytorch的组织结构<a href=\"https://github.com/pytorch/pytorch\">github</a>，总是一头雾水，这篇文章提供了一个帮助，去了解pytorch是怎样一步步组织起来的。</p>\n</blockquote>\n<blockquote>\n<ol start=\"0\">\n<li>cuda算子，一般是由核函数组成的.cu和.cpp文件</li>\n<li>cuda封装，提供参数，调用算子，不进行存储</li>\n<li>autograd算子，存储求导所需要的临时变量</li>\n<li>function封装，在上一层的基础上做一些健壮性工作</li>\n<li>Module封装，把函数封装成类，为的是实现永久性存储</li>\n</ol>\n</blockquote>\n<h2 id=\"torch中同一个功能，不同层级的封装有什么用？我应该用什么层级的封装？\"><a href=\"#torch中同一个功能，不同层级的封装有什么用？我应该用什么层级的封装？\" class=\"headerlink\" title=\"torch中同一个功能，不同层级的封装有什么用？我应该用什么层级的封装？\"></a>torch中同一个功能，不同层级的封装有什么用？我应该用什么层级的封装？</h2><p>1:首先我们说在torch中你能看到的最基础封装是cuda封装，或者叫<a href=\"https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=cuda%E7%AE%97%E5%AD%90&zhida_source=entity\">cuda算子</a>，我们算它是1级封装。（方便起见我们这里忽略triton等其他方式实现的算子）</p>\n<p>这个封装层级下你可能会看到这样的调用方式：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GEMM_cuda.fwd(mat1,mat2)</span><br><span class=\"line\">GEMM_cuda.bwd(grad_o,mat1,mat2)</span><br></pre></td></tr></table></figure>\n\n<p>这种封装是python封装的最底层，它是在调用更底层的c++算子，实现矩阵运算的正向传播和反向传播。</p>\n<p>c++这个层级的算子只负责计算，计算之后相应的内存空间就销毁，不会存储任何东西。</p>\n<p>但我们知道torch是支持自动求导的，自动求导是依据链式法则实现的。一个简单的乘法：y&#x3D;wx，计算w的导数：dy&#x2F;dw &#x3D; x，你会发现w的导数就是x，那么在我们计算w的导数时，就需要知道x，而x是正向传播时传递过来的，因此我们需要在正向传播时存下这个x。上面又说了cuda算子只负责计算，不负责存储，那么我们就需要更高一级的封装，来存储这些求导所使用的临时变量。</p>\n<hr>\n<p>2: 在cuda算子之上的2级封装是<a href=\"https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=autograd%E7%AE%97%E5%AD%90&zhida_source=entity\">autograd算子</a>，它是通过继承torch.autograd.Function来实现的。这个层级的封装就是为了存储求导所需要的临时变量。从这一个层级开始就都是python代码了。</p>\n<p>你可能见到这种形式的autograd算子：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import torch</span><br><span class=\"line\">class TensorModelParallelCrossEntropy(torch.autograd.Function):</span><br><span class=\"line\">    @staticmethod</span><br><span class=\"line\">    def forward(ctx, logits, target, label_smoothing=0.0):</span><br><span class=\"line\">        # do something</span><br><span class=\"line\">        ctx.save_for_backward(...)</span><br><span class=\"line\">        return loss</span><br><span class=\"line\"></span><br><span class=\"line\">    @staticmethod</span><br><span class=\"line\">    def backward(ctx, grad_output):</span><br><span class=\"line\">        # do something</span><br><span class=\"line\">        ... = ctx.saved_tensors</span><br><span class=\"line\">        return grad_input, None, None</span><br></pre></td></tr></table></figure>\n\n<p>你可以看到这种算子中会存在一个save_for_backward函数，专门存储反向传播需要的临时变量。</p>\n<p>这种算子可以通过下面这种方式调用：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ce_loss = TensorModelParallelCrossEntropy.apply(logits,labels)</span><br></pre></td></tr></table></figure>\n\n<p>你可以看到调用这种算子并不是通过使用它的forward或者backward函数，而是使用apply函数。这里torch会进行一些封装，例如调用apply后，会用forward进行计算，并将backward添加到tensor的grad_fn属性计算图中，求导时自动调用。会在使用了torch.no_grad()上下文，不需要求导时，自动抛弃掉save_for_backward存储的张量。但是这种层级用的也不是太常见，首先观察forward函数的输入参数和backward的输出参数。backward函数返回的梯度数量必须和forward输入参数的数量相同，但是可以用None占位。比如target是标签，label_smoothing是超参，不可学习，不需要导数，这里就会用None占位。因此当你需要某一个功能的时候，需要严格的选择你需要的autograd算子，达到最佳的计算效率，不需要计算的东西不要算。</p>\n<hr>\n<p>3: 接下来就是第3级function封装。function封装的作用就是增加autograd算子的灵活性和健壮性，比如做一些异常检测，默认值填补，找到合适的autograd算子分发等等，比如这样：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def linear_with_grad_accumulation_and_async_allreduce(input,weight,bias,lora_a=None,lora_b=None):</span><br><span class=\"line\">  assert input.is_cuda() and weight.is_cuda()</span><br><span class=\"line\">  if lora_a is not None and lora_b is not None:</span><br><span class=\"line\">    return LoraLinearWithGradAccumulationAndAsyncCommunication.apply(input,weight,bias,lora_a,lora_b)</span><br><span class=\"line\">  else:</span><br><span class=\"line\">    return LinearWithGradAccumulationAndAsyncCommunication.apply(input,weight,bias)</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=torch.nn&zhida_source=entity\">torch.nn</a>.functional里面的函数就是这一级封装，这一级的函数对于大部分的人来说已经可以拿来用了，比如：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from torch.nn.functional import linear,dropout</span><br><span class=\"line\">linear(input,weight,bias)</span><br><span class=\"line\">dropout(input,p=0.1,training=True)</span><br></pre></td></tr></table></figure>\n\n<p>但是这个层级的封装依旧只会存储正、反向传播的临时变量，并不会存储一些持久化存在的变量。</p>\n<p>比如看到linear函数，它的输入有input、weight、bias，其中input是一个临时变量，你的模型输入数据了，input就有，不输入就没有，输入不同的值input也不同。但是weight和bias是模型定义的时候就存在的，与你是否正向传播无关，也不会随着你输入input的值不同而改变。看到dropout函数，丢弃率p和模型当前是处于训练状态还是推理状态，也不是一个会每次都变的值。所以我们还需要一层封装来存储这些不会临时改变的东西。</p>\n<hr>\n<p>4:这第4级封装就是torch的Module级别封装，也就是题主题目中提到的“用类实现”。类似这个样子：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class Linear(torch.nn.Module):</span><br><span class=\"line\">  </span><br><span class=\"line\">    def __init__(self, in_features: int, out_features: int, bias: bool = True,</span><br><span class=\"line\">                 device=None, dtype=None) -&gt; None:</span><br><span class=\"line\">        factory_kwargs = &#123;&#x27;device&#x27;: device, &#x27;dtype&#x27;: dtype&#125;</span><br><span class=\"line\">        super().__init__()</span><br><span class=\"line\">        self.in_features = in_features</span><br><span class=\"line\">        self.out_features = out_features</span><br><span class=\"line\">        self.weight = torch.nn.Parameter(torch.empty((out_features, in_features), **factory_kwargs))</span><br><span class=\"line\">        if bias:</span><br><span class=\"line\">            self.bias = torch.nn.Parameter(torch.empty(out_features, **factory_kwargs))</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            self.register_parameter(&#x27;bias&#x27;, None)</span><br><span class=\"line\">        self.reset_parameters()</span><br><span class=\"line\"></span><br><span class=\"line\">    def reset_parameters(self) -&gt; None:</span><br><span class=\"line\">        init.kaiming_uniform_(self.weight, a=math.sqrt(5))</span><br><span class=\"line\">        if self.bias is not None:</span><br><span class=\"line\">            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)</span><br><span class=\"line\">            bound = 1 / math.sqrt(fan_in) if fan_in &gt; 0 else 0</span><br><span class=\"line\">            init.uniform_(self.bias, -bound, bound)</span><br><span class=\"line\"></span><br><span class=\"line\">    def forward(self, input: Tensor) -&gt; Tensor:</span><br><span class=\"line\">        return F.linear(input, self.weight, self.bias)</span><br></pre></td></tr></table></figure>\n\n<p>它会帮你定义持久存储的参数weight和bias，会帮你自动初始化这些参数，比如使用kaiming初始化。在你调用这个类创建的实例时，它会调用这个类的forward函数：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">layer = Linear(10,5,bias=False)</span><br><span class=\"line\">x = torch.randn(2,10)</span><br><span class=\"line\">y = layer(x)</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=Module%E5%B0%81%E8%A3%85&zhida_source=entity\">Module封装</a>和autograd封装一样，调用和定义的函数名是不同的，同样是因为torch后台帮你做了一些操作，比如判断类是否有某个属性，判断类多重继承时应该调用谁的函数，给正反向传播的输入和输出添加一些钩子函数等。</p>\n<p>到这里题主的问题，为什么要用类，为什么不用函数就已经很明确了。不想管理持久化的变量，就用Module封装，想要手动管理，就用function封装。想要自定义正反向传播的计算方法，就去写autograd算子，想炸裂提效，做算子融合，就去写cuda或者triton算子。</p>\n<blockquote>\n<p>作者：真中合欢<br>链接：<a href=\"https://www.zhihu.com/question/677187311/answer/3780895706\">https://www.zhihu.com/question/677187311/answer/3780895706</a></p>\n</blockquote>\n","excerpt":"","more":"<blockquote>\n<p>作为初学者,这篇文章对我非常有帮助。如果直接看pytorch的组织结构<a href=\"https://github.com/pytorch/pytorch\">github</a>，总是一头雾水，这篇文章提供了一个帮助，去了解pytorch是怎样一步步组织起来的。</p>\n</blockquote>\n<blockquote>\n<ol start=\"0\">\n<li>cuda算子，一般是由核函数组成的.cu和.cpp文件</li>\n<li>cuda封装，提供参数，调用算子，不进行存储</li>\n<li>autograd算子，存储求导所需要的临时变量</li>\n<li>function封装，在上一层的基础上做一些健壮性工作</li>\n<li>Module封装，把函数封装成类，为的是实现永久性存储</li>\n</ol>\n</blockquote>\n<h2 id=\"torch中同一个功能，不同层级的封装有什么用？我应该用什么层级的封装？\"><a href=\"#torch中同一个功能，不同层级的封装有什么用？我应该用什么层级的封装？\" class=\"headerlink\" title=\"torch中同一个功能，不同层级的封装有什么用？我应该用什么层级的封装？\"></a>torch中同一个功能，不同层级的封装有什么用？我应该用什么层级的封装？</h2><p>1:首先我们说在torch中你能看到的最基础封装是cuda封装，或者叫<a href=\"https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=cuda%E7%AE%97%E5%AD%90&zhida_source=entity\">cuda算子</a>，我们算它是1级封装。（方便起见我们这里忽略triton等其他方式实现的算子）</p>\n<p>这个封装层级下你可能会看到这样的调用方式：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">GEMM_cuda.fwd(mat1,mat2)</span><br><span class=\"line\">GEMM_cuda.bwd(grad_o,mat1,mat2)</span><br></pre></td></tr></table></figure>\n\n<p>这种封装是python封装的最底层，它是在调用更底层的c++算子，实现矩阵运算的正向传播和反向传播。</p>\n<p>c++这个层级的算子只负责计算，计算之后相应的内存空间就销毁，不会存储任何东西。</p>\n<p>但我们知道torch是支持自动求导的，自动求导是依据链式法则实现的。一个简单的乘法：y&#x3D;wx，计算w的导数：dy&#x2F;dw &#x3D; x，你会发现w的导数就是x，那么在我们计算w的导数时，就需要知道x，而x是正向传播时传递过来的，因此我们需要在正向传播时存下这个x。上面又说了cuda算子只负责计算，不负责存储，那么我们就需要更高一级的封装，来存储这些求导所使用的临时变量。</p>\n<hr>\n<p>2: 在cuda算子之上的2级封装是<a href=\"https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=autograd%E7%AE%97%E5%AD%90&zhida_source=entity\">autograd算子</a>，它是通过继承torch.autograd.Function来实现的。这个层级的封装就是为了存储求导所需要的临时变量。从这一个层级开始就都是python代码了。</p>\n<p>你可能见到这种形式的autograd算子：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">import torch</span><br><span class=\"line\">class TensorModelParallelCrossEntropy(torch.autograd.Function):</span><br><span class=\"line\">    @staticmethod</span><br><span class=\"line\">    def forward(ctx, logits, target, label_smoothing=0.0):</span><br><span class=\"line\">        # do something</span><br><span class=\"line\">        ctx.save_for_backward(...)</span><br><span class=\"line\">        return loss</span><br><span class=\"line\"></span><br><span class=\"line\">    @staticmethod</span><br><span class=\"line\">    def backward(ctx, grad_output):</span><br><span class=\"line\">        # do something</span><br><span class=\"line\">        ... = ctx.saved_tensors</span><br><span class=\"line\">        return grad_input, None, None</span><br></pre></td></tr></table></figure>\n\n<p>你可以看到这种算子中会存在一个save_for_backward函数，专门存储反向传播需要的临时变量。</p>\n<p>这种算子可以通过下面这种方式调用：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ce_loss = TensorModelParallelCrossEntropy.apply(logits,labels)</span><br></pre></td></tr></table></figure>\n\n<p>你可以看到调用这种算子并不是通过使用它的forward或者backward函数，而是使用apply函数。这里torch会进行一些封装，例如调用apply后，会用forward进行计算，并将backward添加到tensor的grad_fn属性计算图中，求导时自动调用。会在使用了torch.no_grad()上下文，不需要求导时，自动抛弃掉save_for_backward存储的张量。但是这种层级用的也不是太常见，首先观察forward函数的输入参数和backward的输出参数。backward函数返回的梯度数量必须和forward输入参数的数量相同，但是可以用None占位。比如target是标签，label_smoothing是超参，不可学习，不需要导数，这里就会用None占位。因此当你需要某一个功能的时候，需要严格的选择你需要的autograd算子，达到最佳的计算效率，不需要计算的东西不要算。</p>\n<hr>\n<p>3: 接下来就是第3级function封装。function封装的作用就是增加autograd算子的灵活性和健壮性，比如做一些异常检测，默认值填补，找到合适的autograd算子分发等等，比如这样：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def linear_with_grad_accumulation_and_async_allreduce(input,weight,bias,lora_a=None,lora_b=None):</span><br><span class=\"line\">  assert input.is_cuda() and weight.is_cuda()</span><br><span class=\"line\">  if lora_a is not None and lora_b is not None:</span><br><span class=\"line\">    return LoraLinearWithGradAccumulationAndAsyncCommunication.apply(input,weight,bias,lora_a,lora_b)</span><br><span class=\"line\">  else:</span><br><span class=\"line\">    return LinearWithGradAccumulationAndAsyncCommunication.apply(input,weight,bias)</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=torch.nn&zhida_source=entity\">torch.nn</a>.functional里面的函数就是这一级封装，这一级的函数对于大部分的人来说已经可以拿来用了，比如：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">from torch.nn.functional import linear,dropout</span><br><span class=\"line\">linear(input,weight,bias)</span><br><span class=\"line\">dropout(input,p=0.1,training=True)</span><br></pre></td></tr></table></figure>\n\n<p>但是这个层级的封装依旧只会存储正、反向传播的临时变量，并不会存储一些持久化存在的变量。</p>\n<p>比如看到linear函数，它的输入有input、weight、bias，其中input是一个临时变量，你的模型输入数据了，input就有，不输入就没有，输入不同的值input也不同。但是weight和bias是模型定义的时候就存在的，与你是否正向传播无关，也不会随着你输入input的值不同而改变。看到dropout函数，丢弃率p和模型当前是处于训练状态还是推理状态，也不是一个会每次都变的值。所以我们还需要一层封装来存储这些不会临时改变的东西。</p>\n<hr>\n<p>4:这第4级封装就是torch的Module级别封装，也就是题主题目中提到的“用类实现”。类似这个样子：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class Linear(torch.nn.Module):</span><br><span class=\"line\">  </span><br><span class=\"line\">    def __init__(self, in_features: int, out_features: int, bias: bool = True,</span><br><span class=\"line\">                 device=None, dtype=None) -&gt; None:</span><br><span class=\"line\">        factory_kwargs = &#123;&#x27;device&#x27;: device, &#x27;dtype&#x27;: dtype&#125;</span><br><span class=\"line\">        super().__init__()</span><br><span class=\"line\">        self.in_features = in_features</span><br><span class=\"line\">        self.out_features = out_features</span><br><span class=\"line\">        self.weight = torch.nn.Parameter(torch.empty((out_features, in_features), **factory_kwargs))</span><br><span class=\"line\">        if bias:</span><br><span class=\"line\">            self.bias = torch.nn.Parameter(torch.empty(out_features, **factory_kwargs))</span><br><span class=\"line\">        else:</span><br><span class=\"line\">            self.register_parameter(&#x27;bias&#x27;, None)</span><br><span class=\"line\">        self.reset_parameters()</span><br><span class=\"line\"></span><br><span class=\"line\">    def reset_parameters(self) -&gt; None:</span><br><span class=\"line\">        init.kaiming_uniform_(self.weight, a=math.sqrt(5))</span><br><span class=\"line\">        if self.bias is not None:</span><br><span class=\"line\">            fan_in, _ = init._calculate_fan_in_and_fan_out(self.weight)</span><br><span class=\"line\">            bound = 1 / math.sqrt(fan_in) if fan_in &gt; 0 else 0</span><br><span class=\"line\">            init.uniform_(self.bias, -bound, bound)</span><br><span class=\"line\"></span><br><span class=\"line\">    def forward(self, input: Tensor) -&gt; Tensor:</span><br><span class=\"line\">        return F.linear(input, self.weight, self.bias)</span><br></pre></td></tr></table></figure>\n\n<p>它会帮你定义持久存储的参数weight和bias，会帮你自动初始化这些参数，比如使用kaiming初始化。在你调用这个类创建的实例时，它会调用这个类的forward函数：</p>\n<figure class=\"highlight text\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">layer = Linear(10,5,bias=False)</span><br><span class=\"line\">x = torch.randn(2,10)</span><br><span class=\"line\">y = layer(x)</span><br></pre></td></tr></table></figure>\n\n<p><a href=\"https://zhida.zhihu.com/search?content_id=691781227&content_type=Answer&match_order=1&q=Module%E5%B0%81%E8%A3%85&zhida_source=entity\">Module封装</a>和autograd封装一样，调用和定义的函数名是不同的，同样是因为torch后台帮你做了一些操作，比如判断类是否有某个属性，判断类多重继承时应该调用谁的函数，给正反向传播的输入和输出添加一些钩子函数等。</p>\n<p>到这里题主的问题，为什么要用类，为什么不用函数就已经很明确了。不想管理持久化的变量，就用Module封装，想要手动管理，就用function封装。想要自定义正反向传播的计算方法，就去写autograd算子，想炸裂提效，做算子融合，就去写cuda或者triton算子。</p>\n<blockquote>\n<p>作者：真中合欢<br>链接：<a href=\"https://www.zhihu.com/question/677187311/answer/3780895706\">https://www.zhihu.com/question/677187311/answer/3780895706</a></p>\n</blockquote>\n"},{"title":"二十年前的相机","date":"2025-07-13T02:13:40.000Z","_content":"# Canon PowerShot G5\n\n出于“还能用的东西统统留着”的原则，经常能从家里的角落找到老古董，感觉时间仿佛静止了一般。\n这台佳能相机于2003年上市，04年购入，据回忆当时的价格大约5000元。我对相机技术并不是很了解，不过当年想必也是比较先进的机型。在Amazon上可以找到当时的评价：\n\n> I bought this camera to replace a 2mp camera that allowed no control over aperture and speed and to give me the greater resolution that would allow larger than 8x10 prints. I was very pleased with the menu structure and layout of the controls but I was very surprised to see the lens barrel visible through the optical viewfinder, obscuring the lower left part of a shot unless the camera is zoomed in. The lens is outstanding, and shots taken at ISO 50 are wonderfully free of noise even in low light. What killed the camera for me is the autofocus. For some reason it often has a hard time finding focus. In several situations from macro to landscape and at various light levels the autofocus would hunt for seconds and then occasionally would give up and lose focus entirely. The conditions mentioned in the manual that might cause difficulty with focus were not present. Of course, I could focus manually but that can be a tedious task using the LCD display (and not just with this camera), especially in bright light. The camera has a good feel and is easy to use but I finally gave it up from the frustration with focus. I bought an Olympus C-5050 which is not quite so easy to use but the autofocus is rapid and reliable. I frequently see a shot where I must get the camera out and on it quickly and the G5 couldn't be counted on.\n\n---\n\n这则评价发布于2003年，对焦速度慢，经常对焦错误——到这确实是非常中肯的评价。不过放在今天，复古的自动对焦过程、伸缩镜头发出的机械声反而让人狂喜。译文如下：\n\n> 我购买这台相机是为了替换一台200万像素的相机，那台相机无法调节光圈和快门速度，而这台相机则能提供更高的分辨率，支持打印大于8x10英寸的相片。我对相机的菜单结构和控制布局非常满意，但令我惊讶的是，通过光学取景器可以看到镜头筒，这会遮挡画面左下角的部分，除非将相机进行变焦。镜头表现出色，即使在低光环境下，ISO 50拍摄的画面也几乎没有噪点。但自动对焦功能让我对这台相机失去了兴趣。不知何故，它经常难以找到对焦点。在从微距到风景的多种拍摄场景和不同光线条件下，自动对焦系统会搜索数秒，偶尔甚至会放弃对焦并完全失焦。而说明书中提到的可能导致对焦困难的条件并未出现。当然，我可以手动对焦，但使用LCD屏幕进行手动对焦（不仅限于这台相机）在强光下会非常繁琐。这台相机手感良好且易于使用，但我最终因对焦问题而放弃了它。我购买了奥林巴斯C-5050，虽然它使用起来没有那么方便，但自动对焦速度快且可靠。我经常遇到需要迅速拿出相机并快速拍摄的场景，而G5无法满足这一需求。\n\n最后一次使用大概是在12或者13年的儿童节（里面的cf卡中竟然还有没导出的相片），随后就一直放在地下室。中间地下室遭过一次贼，居然幸免遇难。今天找到，箱包完整，充电后一切功能正常，质量实在过硬。\n\n{% asset_img \"包装.jpg\"%}\n照片由G5拍摄，500万像素还是相当清晰。盒子八角尖尖，不错。\n\n{% asset_img \"内部.jpg\"%}\n打开盒子，还能闻到十年前的~~灰尘~~空气。说明书完整，保修单还一次都没用过。\n\n{% asset_img \"相机.jpg\"%}\n给相机来一张大头照，握把已经老化的黏糊糊了，有点可惜。\n本来想展示一下细节，发现已经有人做出来了[测评](https://www.bilibili.com/video/BV1He4y1h7Ee/?spm_id_from=333.337.search-card.all.click&vd_source=afec0ec631ec084a74fcdd3c2f49a6ab)\n\n<iframe src=\"https://player.bilibili.com/player.html?isOutside=true&aid=560256914&bvid=BV1He4y1h7Ee&cid=826868209&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" autoplay=false></iframe>\n\n照相功能放在今天来看依然不错，带着可爱的色彩，只是视频的情况就不敢恭维了——这是考古人员再cf卡中读到的一段视频：\n\n<iframe src=\"https://player.bilibili.com/player.html?isOutside=true&aid=114846385315535&bvid=BV1hUuPzBE2Q&cid=31019304770&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" autoplay=false></iframe>\n\n其实这个节目我是有上去表演的，节目的内容就是大家跟着哆啦A梦的音乐跳舞。参加表演的大多是女孩子，这项节目大概只有我们三个男生参加，其中一个是我的好朋友，他早熟又擅于表现，所以总是很受欢迎；另一个同学聪明沉稳，他是我们中最像大人的一个。本人属实是其中最笨拙的，彩排时就跟在上述第二个同学后面有样学样，表演时毫不协调只能滥竽充数了。\n想到这，不禁困惑当时为什么参加这个活动，也许是为了配合好兄弟的表演罢。之后再上中学和大学，却也没有参加过跳舞这样的节目了。\n\n最后怀着激动的心情用这台相机照一张像，完成与小时候的交接：\n{% asset_img \"照片.jpg\" %}\n~~对焦没有对到镜子里的虚像反而对到镜框上去了啊啊啊啊啊啊~~\n","source":"_posts/二十年前的相机.md","raw":"---\ntitle: 二十年前的相机\ndate: 2025-07-13 10:13:40\ncategories:\n  - 日志\ntags:\n  - 摄影\n---\n# Canon PowerShot G5\n\n出于“还能用的东西统统留着”的原则，经常能从家里的角落找到老古董，感觉时间仿佛静止了一般。\n这台佳能相机于2003年上市，04年购入，据回忆当时的价格大约5000元。我对相机技术并不是很了解，不过当年想必也是比较先进的机型。在Amazon上可以找到当时的评价：\n\n> I bought this camera to replace a 2mp camera that allowed no control over aperture and speed and to give me the greater resolution that would allow larger than 8x10 prints. I was very pleased with the menu structure and layout of the controls but I was very surprised to see the lens barrel visible through the optical viewfinder, obscuring the lower left part of a shot unless the camera is zoomed in. The lens is outstanding, and shots taken at ISO 50 are wonderfully free of noise even in low light. What killed the camera for me is the autofocus. For some reason it often has a hard time finding focus. In several situations from macro to landscape and at various light levels the autofocus would hunt for seconds and then occasionally would give up and lose focus entirely. The conditions mentioned in the manual that might cause difficulty with focus were not present. Of course, I could focus manually but that can be a tedious task using the LCD display (and not just with this camera), especially in bright light. The camera has a good feel and is easy to use but I finally gave it up from the frustration with focus. I bought an Olympus C-5050 which is not quite so easy to use but the autofocus is rapid and reliable. I frequently see a shot where I must get the camera out and on it quickly and the G5 couldn't be counted on.\n\n---\n\n这则评价发布于2003年，对焦速度慢，经常对焦错误——到这确实是非常中肯的评价。不过放在今天，复古的自动对焦过程、伸缩镜头发出的机械声反而让人狂喜。译文如下：\n\n> 我购买这台相机是为了替换一台200万像素的相机，那台相机无法调节光圈和快门速度，而这台相机则能提供更高的分辨率，支持打印大于8x10英寸的相片。我对相机的菜单结构和控制布局非常满意，但令我惊讶的是，通过光学取景器可以看到镜头筒，这会遮挡画面左下角的部分，除非将相机进行变焦。镜头表现出色，即使在低光环境下，ISO 50拍摄的画面也几乎没有噪点。但自动对焦功能让我对这台相机失去了兴趣。不知何故，它经常难以找到对焦点。在从微距到风景的多种拍摄场景和不同光线条件下，自动对焦系统会搜索数秒，偶尔甚至会放弃对焦并完全失焦。而说明书中提到的可能导致对焦困难的条件并未出现。当然，我可以手动对焦，但使用LCD屏幕进行手动对焦（不仅限于这台相机）在强光下会非常繁琐。这台相机手感良好且易于使用，但我最终因对焦问题而放弃了它。我购买了奥林巴斯C-5050，虽然它使用起来没有那么方便，但自动对焦速度快且可靠。我经常遇到需要迅速拿出相机并快速拍摄的场景，而G5无法满足这一需求。\n\n最后一次使用大概是在12或者13年的儿童节（里面的cf卡中竟然还有没导出的相片），随后就一直放在地下室。中间地下室遭过一次贼，居然幸免遇难。今天找到，箱包完整，充电后一切功能正常，质量实在过硬。\n\n{% asset_img \"包装.jpg\"%}\n照片由G5拍摄，500万像素还是相当清晰。盒子八角尖尖，不错。\n\n{% asset_img \"内部.jpg\"%}\n打开盒子，还能闻到十年前的~~灰尘~~空气。说明书完整，保修单还一次都没用过。\n\n{% asset_img \"相机.jpg\"%}\n给相机来一张大头照，握把已经老化的黏糊糊了，有点可惜。\n本来想展示一下细节，发现已经有人做出来了[测评](https://www.bilibili.com/video/BV1He4y1h7Ee/?spm_id_from=333.337.search-card.all.click&vd_source=afec0ec631ec084a74fcdd3c2f49a6ab)\n\n<iframe src=\"https://player.bilibili.com/player.html?isOutside=true&aid=560256914&bvid=BV1He4y1h7Ee&cid=826868209&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" autoplay=false></iframe>\n\n照相功能放在今天来看依然不错，带着可爱的色彩，只是视频的情况就不敢恭维了——这是考古人员再cf卡中读到的一段视频：\n\n<iframe src=\"https://player.bilibili.com/player.html?isOutside=true&aid=114846385315535&bvid=BV1hUuPzBE2Q&cid=31019304770&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" autoplay=false></iframe>\n\n其实这个节目我是有上去表演的，节目的内容就是大家跟着哆啦A梦的音乐跳舞。参加表演的大多是女孩子，这项节目大概只有我们三个男生参加，其中一个是我的好朋友，他早熟又擅于表现，所以总是很受欢迎；另一个同学聪明沉稳，他是我们中最像大人的一个。本人属实是其中最笨拙的，彩排时就跟在上述第二个同学后面有样学样，表演时毫不协调只能滥竽充数了。\n想到这，不禁困惑当时为什么参加这个活动，也许是为了配合好兄弟的表演罢。之后再上中学和大学，却也没有参加过跳舞这样的节目了。\n\n最后怀着激动的心情用这台相机照一张像，完成与小时候的交接：\n{% asset_img \"照片.jpg\" %}\n~~对焦没有对到镜子里的虚像反而对到镜框上去了啊啊啊啊啊啊~~\n","slug":"二十年前的相机","published":1,"updated":"2025-10-11T09:48:40.219Z","_id":"cmf9mvzsv0006ad9l65l0eowv","comments":1,"layout":"post","photos":[],"content":"<h1 id=\"Canon-PowerShot-G5\"><a href=\"#Canon-PowerShot-G5\" class=\"headerlink\" title=\"Canon PowerShot G5\"></a>Canon PowerShot G5</h1><p>出于“还能用的东西统统留着”的原则，经常能从家里的角落找到老古董，感觉时间仿佛静止了一般。<br>这台佳能相机于2003年上市，04年购入，据回忆当时的价格大约5000元。我对相机技术并不是很了解，不过当年想必也是比较先进的机型。在Amazon上可以找到当时的评价：</p>\n<blockquote>\n<p>I bought this camera to replace a 2mp camera that allowed no control over aperture and speed and to give me the greater resolution that would allow larger than 8x10 prints. I was very pleased with the menu structure and layout of the controls but I was very surprised to see the lens barrel visible through the optical viewfinder, obscuring the lower left part of a shot unless the camera is zoomed in. The lens is outstanding, and shots taken at ISO 50 are wonderfully free of noise even in low light. What killed the camera for me is the autofocus. For some reason it often has a hard time finding focus. In several situations from macro to landscape and at various light levels the autofocus would hunt for seconds and then occasionally would give up and lose focus entirely. The conditions mentioned in the manual that might cause difficulty with focus were not present. Of course, I could focus manually but that can be a tedious task using the LCD display (and not just with this camera), especially in bright light. The camera has a good feel and is easy to use but I finally gave it up from the frustration with focus. I bought an Olympus C-5050 which is not quite so easy to use but the autofocus is rapid and reliable. I frequently see a shot where I must get the camera out and on it quickly and the G5 couldn’t be counted on.</p>\n</blockquote>\n<hr>\n<p>这则评价发布于2003年，对焦速度慢，经常对焦错误——到这确实是非常中肯的评价。不过放在今天，复古的自动对焦过程、伸缩镜头发出的机械声反而让人狂喜。译文如下：</p>\n<blockquote>\n<p>我购买这台相机是为了替换一台200万像素的相机，那台相机无法调节光圈和快门速度，而这台相机则能提供更高的分辨率，支持打印大于8x10英寸的相片。我对相机的菜单结构和控制布局非常满意，但令我惊讶的是，通过光学取景器可以看到镜头筒，这会遮挡画面左下角的部分，除非将相机进行变焦。镜头表现出色，即使在低光环境下，ISO 50拍摄的画面也几乎没有噪点。但自动对焦功能让我对这台相机失去了兴趣。不知何故，它经常难以找到对焦点。在从微距到风景的多种拍摄场景和不同光线条件下，自动对焦系统会搜索数秒，偶尔甚至会放弃对焦并完全失焦。而说明书中提到的可能导致对焦困难的条件并未出现。当然，我可以手动对焦，但使用LCD屏幕进行手动对焦（不仅限于这台相机）在强光下会非常繁琐。这台相机手感良好且易于使用，但我最终因对焦问题而放弃了它。我购买了奥林巴斯C-5050，虽然它使用起来没有那么方便，但自动对焦速度快且可靠。我经常遇到需要迅速拿出相机并快速拍摄的场景，而G5无法满足这一需求。</p>\n</blockquote>\n<p>最后一次使用大概是在12或者13年的儿童节（里面的cf卡中竟然还有没导出的相片），随后就一直放在地下室。中间地下室遭过一次贼，居然幸免遇难。今天找到，箱包完整，充电后一切功能正常，质量实在过硬。</p>\n<img src=\"/2025/07/13/%E4%BA%8C%E5%8D%81%E5%B9%B4%E5%89%8D%E7%9A%84%E7%9B%B8%E6%9C%BA/%E5%8C%85%E8%A3%85.jpg\" class=\"\">\n<p>照片由G5拍摄，500万像素还是相当清晰。盒子八角尖尖，不错。</p>\n<img src=\"/2025/07/13/%E4%BA%8C%E5%8D%81%E5%B9%B4%E5%89%8D%E7%9A%84%E7%9B%B8%E6%9C%BA/%E5%86%85%E9%83%A8.jpg\" class=\"\">\n<p>打开盒子，还能闻到十年前的<del>灰尘</del>空气。说明书完整，保修单还一次都没用过。</p>\n<img src=\"/2025/07/13/%E4%BA%8C%E5%8D%81%E5%B9%B4%E5%89%8D%E7%9A%84%E7%9B%B8%E6%9C%BA/%E7%9B%B8%E6%9C%BA.jpg\" class=\"\">\n<p>给相机来一张大头照，握把已经老化的黏糊糊了，有点可惜。<br>本来想展示一下细节，发现已经有人做出来了<a href=\"https://www.bilibili.com/video/BV1He4y1h7Ee/?spm_id_from=333.337.search-card.all.click&vd_source=afec0ec631ec084a74fcdd3c2f49a6ab\">测评</a></p>\n<iframe src=\"https://player.bilibili.com/player.html?isOutside=true&aid=560256914&bvid=BV1He4y1h7Ee&cid=826868209&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" autoplay=false></iframe>\n\n<p>照相功能放在今天来看依然不错，带着可爱的色彩，只是视频的情况就不敢恭维了——这是考古人员再cf卡中读到的一段视频：</p>\n<iframe src=\"https://player.bilibili.com/player.html?isOutside=true&aid=114846385315535&bvid=BV1hUuPzBE2Q&cid=31019304770&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" autoplay=false></iframe>\n\n<p>其实这个节目我是有上去表演的，节目的内容就是大家跟着哆啦A梦的音乐跳舞。参加表演的大多是女孩子，这项节目大概只有我们三个男生参加，其中一个是我的好朋友，他早熟又擅于表现，所以总是很受欢迎；另一个同学聪明沉稳，他是我们中最像大人的一个。本人属实是其中最笨拙的，彩排时就跟在上述第二个同学后面有样学样，表演时毫不协调只能滥竽充数了。<br>想到这，不禁困惑当时为什么参加这个活动，也许是为了配合好兄弟的表演罢。之后再上中学和大学，却也没有参加过跳舞这样的节目了。</p>\n<p>最后怀着激动的心情用这台相机照一张像，完成与小时候的交接：</p>\n<img src=\"/2025/07/13/%E4%BA%8C%E5%8D%81%E5%B9%B4%E5%89%8D%E7%9A%84%E7%9B%B8%E6%9C%BA/%E7%85%A7%E7%89%87.jpg\" class=\"\">\n<p><del>对焦没有对到镜子里的虚像反而对到镜框上去了啊啊啊啊啊啊</del></p>\n","excerpt":"","more":"<h1 id=\"Canon-PowerShot-G5\"><a href=\"#Canon-PowerShot-G5\" class=\"headerlink\" title=\"Canon PowerShot G5\"></a>Canon PowerShot G5</h1><p>出于“还能用的东西统统留着”的原则，经常能从家里的角落找到老古董，感觉时间仿佛静止了一般。<br>这台佳能相机于2003年上市，04年购入，据回忆当时的价格大约5000元。我对相机技术并不是很了解，不过当年想必也是比较先进的机型。在Amazon上可以找到当时的评价：</p>\n<blockquote>\n<p>I bought this camera to replace a 2mp camera that allowed no control over aperture and speed and to give me the greater resolution that would allow larger than 8x10 prints. I was very pleased with the menu structure and layout of the controls but I was very surprised to see the lens barrel visible through the optical viewfinder, obscuring the lower left part of a shot unless the camera is zoomed in. The lens is outstanding, and shots taken at ISO 50 are wonderfully free of noise even in low light. What killed the camera for me is the autofocus. For some reason it often has a hard time finding focus. In several situations from macro to landscape and at various light levels the autofocus would hunt for seconds and then occasionally would give up and lose focus entirely. The conditions mentioned in the manual that might cause difficulty with focus were not present. Of course, I could focus manually but that can be a tedious task using the LCD display (and not just with this camera), especially in bright light. The camera has a good feel and is easy to use but I finally gave it up from the frustration with focus. I bought an Olympus C-5050 which is not quite so easy to use but the autofocus is rapid and reliable. I frequently see a shot where I must get the camera out and on it quickly and the G5 couldn’t be counted on.</p>\n</blockquote>\n<hr>\n<p>这则评价发布于2003年，对焦速度慢，经常对焦错误——到这确实是非常中肯的评价。不过放在今天，复古的自动对焦过程、伸缩镜头发出的机械声反而让人狂喜。译文如下：</p>\n<blockquote>\n<p>我购买这台相机是为了替换一台200万像素的相机，那台相机无法调节光圈和快门速度，而这台相机则能提供更高的分辨率，支持打印大于8x10英寸的相片。我对相机的菜单结构和控制布局非常满意，但令我惊讶的是，通过光学取景器可以看到镜头筒，这会遮挡画面左下角的部分，除非将相机进行变焦。镜头表现出色，即使在低光环境下，ISO 50拍摄的画面也几乎没有噪点。但自动对焦功能让我对这台相机失去了兴趣。不知何故，它经常难以找到对焦点。在从微距到风景的多种拍摄场景和不同光线条件下，自动对焦系统会搜索数秒，偶尔甚至会放弃对焦并完全失焦。而说明书中提到的可能导致对焦困难的条件并未出现。当然，我可以手动对焦，但使用LCD屏幕进行手动对焦（不仅限于这台相机）在强光下会非常繁琐。这台相机手感良好且易于使用，但我最终因对焦问题而放弃了它。我购买了奥林巴斯C-5050，虽然它使用起来没有那么方便，但自动对焦速度快且可靠。我经常遇到需要迅速拿出相机并快速拍摄的场景，而G5无法满足这一需求。</p>\n</blockquote>\n<p>最后一次使用大概是在12或者13年的儿童节（里面的cf卡中竟然还有没导出的相片），随后就一直放在地下室。中间地下室遭过一次贼，居然幸免遇难。今天找到，箱包完整，充电后一切功能正常，质量实在过硬。</p>\n<img src=\"/2025/07/13/%E4%BA%8C%E5%8D%81%E5%B9%B4%E5%89%8D%E7%9A%84%E7%9B%B8%E6%9C%BA/%E5%8C%85%E8%A3%85.jpg\" class=\"\">\n<p>照片由G5拍摄，500万像素还是相当清晰。盒子八角尖尖，不错。</p>\n<img src=\"/2025/07/13/%E4%BA%8C%E5%8D%81%E5%B9%B4%E5%89%8D%E7%9A%84%E7%9B%B8%E6%9C%BA/%E5%86%85%E9%83%A8.jpg\" class=\"\">\n<p>打开盒子，还能闻到十年前的<del>灰尘</del>空气。说明书完整，保修单还一次都没用过。</p>\n<img src=\"/2025/07/13/%E4%BA%8C%E5%8D%81%E5%B9%B4%E5%89%8D%E7%9A%84%E7%9B%B8%E6%9C%BA/%E7%9B%B8%E6%9C%BA.jpg\" class=\"\">\n<p>给相机来一张大头照，握把已经老化的黏糊糊了，有点可惜。<br>本来想展示一下细节，发现已经有人做出来了<a href=\"https://www.bilibili.com/video/BV1He4y1h7Ee/?spm_id_from=333.337.search-card.all.click&vd_source=afec0ec631ec084a74fcdd3c2f49a6ab\">测评</a></p>\n<iframe src=\"https://player.bilibili.com/player.html?isOutside=true&aid=560256914&bvid=BV1He4y1h7Ee&cid=826868209&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" autoplay=false></iframe>\n\n<p>照相功能放在今天来看依然不错，带着可爱的色彩，只是视频的情况就不敢恭维了——这是考古人员再cf卡中读到的一段视频：</p>\n<iframe src=\"https://player.bilibili.com/player.html?isOutside=true&aid=114846385315535&bvid=BV1hUuPzBE2Q&cid=31019304770&p=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" autoplay=false></iframe>\n\n<p>其实这个节目我是有上去表演的，节目的内容就是大家跟着哆啦A梦的音乐跳舞。参加表演的大多是女孩子，这项节目大概只有我们三个男生参加，其中一个是我的好朋友，他早熟又擅于表现，所以总是很受欢迎；另一个同学聪明沉稳，他是我们中最像大人的一个。本人属实是其中最笨拙的，彩排时就跟在上述第二个同学后面有样学样，表演时毫不协调只能滥竽充数了。<br>想到这，不禁困惑当时为什么参加这个活动，也许是为了配合好兄弟的表演罢。之后再上中学和大学，却也没有参加过跳舞这样的节目了。</p>\n<p>最后怀着激动的心情用这台相机照一张像，完成与小时候的交接：</p>\n<img src=\"/2025/07/13/%E4%BA%8C%E5%8D%81%E5%B9%B4%E5%89%8D%E7%9A%84%E7%9B%B8%E6%9C%BA/%E7%85%A7%E7%89%87.jpg\" class=\"\">\n<p><del>对焦没有对到镜子里的虚像反而对到镜框上去了啊啊啊啊啊啊</del></p>\n"},{"title":"从《西征记略》看清代早期满语的使用","date":"2025-07-17T14:57:28.000Z","_content":"> 王万祥，字瑞宇，号铁山，明崇祯十六年（1643年）出生于甘肃会宁。他出身贫寒，三岁时父亲去世，后随母亲投奔在王进宝军中当差的郭姑父。母亲病逝后，王万祥十五岁从戎，后因军功升至福建陆路提督，一生戎马四十余年，历经大小数十战，九死一生。康熙十二年（1673年），王万祥随西宁总兵王进宝前往平叛王辅臣的叛乱。在征战中，他屡立战功，被称为“飞将军”，并将亲身经历编撰成书《西征纪略》\n\n康熙二十四年三月，时任固原中营副将的王万祥，因平叛战功被升任定海镇总兵。\n\n并获得进京陛见的机会。\n\n瀛台见驾的时候，因为离得稍远，且主要是侍卫对他盘问，所以没听到康熙的其他言语。\n\n倒是听到康熙念他的名字了（还有其他武官一起见驾）。\n\n“**皇上顾视数次，与兵部（官员）言我名字，盖汉人的名字。我内心自忖，既传呼我名字数次，便有眷注之意。**”\n\n虽然不知道康熙说的其他话，但王万祥确实听到康熙念叨他名字了，而且听得很真切。\n\n至少名字应该是汉语说的。\n\n然后被侍卫询问，脱衣展示厮杀时留的伤口，如孙权周泰故事。\n\n似乎康熙对此不感兴趣，等王万祥展示完伤疤，抬头一看，康熙已经跟其他官员起驾走了。\n\n王万祥得空看了一遭瀛台景致，然后也退下了。\n\n后得旨又转任兴化镇总兵。\n\n次日被引至乾清门谢恩，又到景山内前殿赐宴，一同出席的有佟国维等。\n\n康熙来了后，见驾行礼，赐茶，赐宴，似乎没有交流，也没有发言。\n\n开宴吃个差不多后，康熙让王万祥近前问话。\n\n但王万祥跪的稍远，康熙就一直说：\n\n**“向前些。”“在近前。”**\n\n这里王万祥能听懂，是汉语无疑了， 王万祥就按命令跪向前了。\n\n然后问话的画风就急转直下了。\n\n康熙问：\n\n“**你是行伍出身么？**”\n\n这应该是正式开始问话了，到这里康熙就开始用满语了。\n\n因为王万祥压根听不懂，一脸懵逼看康熙“不知所云”，茫然向旁边的侍卫进行眼神求助。\n\n但不得不说，王万祥是懂缓解尴尬的，也是会拍马屁的。\n\n因为他解释说：\n\n“**一时不娴 _天 语_ ，未曾答应。**”\n\n好，好一个“天语”。\n\n于是旁边的侍卫，就给他翻译了康熙的问话，王万祥也进行了答复。\n\n康熙的问话，需要侍卫翻译；但王万祥的答话，则不需要翻译。\n\n问答结束，康熙又带着一种大臣、侍卫，出去射箭。\n\n王万祥也展示了箭法。\n\n康熙又就武艺问题，跟王万祥聊了个颠三倒四，双方问答的跟说相声一样。\n\n问：“**尔弓有几个力气？**”\n\n答：“**有六个力气。**”\n\n问：“**尔会耍大刀么？**”\n\n答：“**不会。**”\n\n问：“**会耍梢子棍么？**”\n\n答：“**臣只会笨耍**。”\n\n问：“**怎么叫笨耍？**”\n\n答：“**臣每次临敌时，只是挥刀乱砍，不会耍花样子**。”\n\n【这点倒是大实话，哪有那么多套路对打，都是乱拳打死老师傅。】\n\n这里的问话，虽然没什么营养，可能只是说闲话；但似乎都是用汉语问答的。\n\n虽然王万祥是被侍卫叫到康熙跟前演射的，但他没有明说康熙说“天语”，也没有向侍卫求助进行翻译。\n\n在王万祥答话结束后：\n\n“**上点头，与侍卫说满话，想是说余老实。**”\n\n那刚才演射后的问答，则应该就是说的汉话了。\n\n随后康熙让侍卫射箭，可能是想让他们跟王万祥较量下，结果五个侍卫，三个都射脱靶了。\n\n这下真的“**射箭箭虚发**”了。\n\n看得康熙和王万祥都很无语。\n\n康熙应该是压着怒火，人这么多也不好直接发飙，就对侍卫喷了一通垃圾话，当然肯定是用满语说的。\n\n毕竟有王万祥这个汉人武官在场。\n\n王万祥回忆：\n\n“**上对射箭的侍卫做满话，想是说你们箭脱空，不害羞么？只见侍卫等回答彷徨。**”\n\n然后就打发王万祥退下了。\n\n总结王万祥的这次见驾。\n\n第一次见驾，离得远，不知道康熙说的甚么话？\n\n但是听到康熙念自己名字了。\n\n这里应该跟兵部官说的是满语。\n\n第二次见驾，设宴问话，正式场合，全程满语问答。\n\n转场去射箭，属于私下交流场合，所以用汉语问答，都是些家常话。\n\n侍卫射箭丢了大脸，直接用满语开喷。\n\n> 作者：读书的小猹\n> 链接：https://www.zhihu.com/question/20331441/answer/1923411592244098193\n","source":"_posts/从《西征记略》看清代早期朝廷满汉语的使用.md","raw":"---\ntitle: 从《西征记略》看清代早期满语的使用\ndate: 2025-07-17 22:57:28\ncategories:\n  - 随笔杂记\ntags:\n  - 转载\n---\n> 王万祥，字瑞宇，号铁山，明崇祯十六年（1643年）出生于甘肃会宁。他出身贫寒，三岁时父亲去世，后随母亲投奔在王进宝军中当差的郭姑父。母亲病逝后，王万祥十五岁从戎，后因军功升至福建陆路提督，一生戎马四十余年，历经大小数十战，九死一生。康熙十二年（1673年），王万祥随西宁总兵王进宝前往平叛王辅臣的叛乱。在征战中，他屡立战功，被称为“飞将军”，并将亲身经历编撰成书《西征纪略》\n\n康熙二十四年三月，时任固原中营副将的王万祥，因平叛战功被升任定海镇总兵。\n\n并获得进京陛见的机会。\n\n瀛台见驾的时候，因为离得稍远，且主要是侍卫对他盘问，所以没听到康熙的其他言语。\n\n倒是听到康熙念他的名字了（还有其他武官一起见驾）。\n\n“**皇上顾视数次，与兵部（官员）言我名字，盖汉人的名字。我内心自忖，既传呼我名字数次，便有眷注之意。**”\n\n虽然不知道康熙说的其他话，但王万祥确实听到康熙念叨他名字了，而且听得很真切。\n\n至少名字应该是汉语说的。\n\n然后被侍卫询问，脱衣展示厮杀时留的伤口，如孙权周泰故事。\n\n似乎康熙对此不感兴趣，等王万祥展示完伤疤，抬头一看，康熙已经跟其他官员起驾走了。\n\n王万祥得空看了一遭瀛台景致，然后也退下了。\n\n后得旨又转任兴化镇总兵。\n\n次日被引至乾清门谢恩，又到景山内前殿赐宴，一同出席的有佟国维等。\n\n康熙来了后，见驾行礼，赐茶，赐宴，似乎没有交流，也没有发言。\n\n开宴吃个差不多后，康熙让王万祥近前问话。\n\n但王万祥跪的稍远，康熙就一直说：\n\n**“向前些。”“在近前。”**\n\n这里王万祥能听懂，是汉语无疑了， 王万祥就按命令跪向前了。\n\n然后问话的画风就急转直下了。\n\n康熙问：\n\n“**你是行伍出身么？**”\n\n这应该是正式开始问话了，到这里康熙就开始用满语了。\n\n因为王万祥压根听不懂，一脸懵逼看康熙“不知所云”，茫然向旁边的侍卫进行眼神求助。\n\n但不得不说，王万祥是懂缓解尴尬的，也是会拍马屁的。\n\n因为他解释说：\n\n“**一时不娴 _天 语_ ，未曾答应。**”\n\n好，好一个“天语”。\n\n于是旁边的侍卫，就给他翻译了康熙的问话，王万祥也进行了答复。\n\n康熙的问话，需要侍卫翻译；但王万祥的答话，则不需要翻译。\n\n问答结束，康熙又带着一种大臣、侍卫，出去射箭。\n\n王万祥也展示了箭法。\n\n康熙又就武艺问题，跟王万祥聊了个颠三倒四，双方问答的跟说相声一样。\n\n问：“**尔弓有几个力气？**”\n\n答：“**有六个力气。**”\n\n问：“**尔会耍大刀么？**”\n\n答：“**不会。**”\n\n问：“**会耍梢子棍么？**”\n\n答：“**臣只会笨耍**。”\n\n问：“**怎么叫笨耍？**”\n\n答：“**臣每次临敌时，只是挥刀乱砍，不会耍花样子**。”\n\n【这点倒是大实话，哪有那么多套路对打，都是乱拳打死老师傅。】\n\n这里的问话，虽然没什么营养，可能只是说闲话；但似乎都是用汉语问答的。\n\n虽然王万祥是被侍卫叫到康熙跟前演射的，但他没有明说康熙说“天语”，也没有向侍卫求助进行翻译。\n\n在王万祥答话结束后：\n\n“**上点头，与侍卫说满话，想是说余老实。**”\n\n那刚才演射后的问答，则应该就是说的汉话了。\n\n随后康熙让侍卫射箭，可能是想让他们跟王万祥较量下，结果五个侍卫，三个都射脱靶了。\n\n这下真的“**射箭箭虚发**”了。\n\n看得康熙和王万祥都很无语。\n\n康熙应该是压着怒火，人这么多也不好直接发飙，就对侍卫喷了一通垃圾话，当然肯定是用满语说的。\n\n毕竟有王万祥这个汉人武官在场。\n\n王万祥回忆：\n\n“**上对射箭的侍卫做满话，想是说你们箭脱空，不害羞么？只见侍卫等回答彷徨。**”\n\n然后就打发王万祥退下了。\n\n总结王万祥的这次见驾。\n\n第一次见驾，离得远，不知道康熙说的甚么话？\n\n但是听到康熙念自己名字了。\n\n这里应该跟兵部官说的是满语。\n\n第二次见驾，设宴问话，正式场合，全程满语问答。\n\n转场去射箭，属于私下交流场合，所以用汉语问答，都是些家常话。\n\n侍卫射箭丢了大脸，直接用满语开喷。\n\n> 作者：读书的小猹\n> 链接：https://www.zhihu.com/question/20331441/answer/1923411592244098193\n","slug":"从《西征记略》看清代早期朝廷满汉语的使用","published":1,"updated":"2025-10-11T10:02:07.251Z","_id":"cmf9n1sx80000gn9l2qeg899n","comments":1,"layout":"post","photos":[],"content":"<blockquote>\n<p>王万祥，字瑞宇，号铁山，明崇祯十六年（1643年）出生于甘肃会宁。他出身贫寒，三岁时父亲去世，后随母亲投奔在王进宝军中当差的郭姑父。母亲病逝后，王万祥十五岁从戎，后因军功升至福建陆路提督，一生戎马四十余年，历经大小数十战，九死一生。康熙十二年（1673年），王万祥随西宁总兵王进宝前往平叛王辅臣的叛乱。在征战中，他屡立战功，被称为“飞将军”，并将亲身经历编撰成书《西征纪略》</p>\n</blockquote>\n<p>康熙二十四年三月，时任固原中营副将的王万祥，因平叛战功被升任定海镇总兵。</p>\n<p>并获得进京陛见的机会。</p>\n<p>瀛台见驾的时候，因为离得稍远，且主要是侍卫对他盘问，所以没听到康熙的其他言语。</p>\n<p>倒是听到康熙念他的名字了（还有其他武官一起见驾）。</p>\n<p>“<strong>皇上顾视数次，与兵部（官员）言我名字，盖汉人的名字。我内心自忖，既传呼我名字数次，便有眷注之意。</strong>”</p>\n<p>虽然不知道康熙说的其他话，但王万祥确实听到康熙念叨他名字了，而且听得很真切。</p>\n<p>至少名字应该是汉语说的。</p>\n<p>然后被侍卫询问，脱衣展示厮杀时留的伤口，如孙权周泰故事。</p>\n<p>似乎康熙对此不感兴趣，等王万祥展示完伤疤，抬头一看，康熙已经跟其他官员起驾走了。</p>\n<p>王万祥得空看了一遭瀛台景致，然后也退下了。</p>\n<p>后得旨又转任兴化镇总兵。</p>\n<p>次日被引至乾清门谢恩，又到景山内前殿赐宴，一同出席的有佟国维等。</p>\n<p>康熙来了后，见驾行礼，赐茶，赐宴，似乎没有交流，也没有发言。</p>\n<p>开宴吃个差不多后，康熙让王万祥近前问话。</p>\n<p>但王万祥跪的稍远，康熙就一直说：</p>\n<p><strong>“向前些。”“在近前。”</strong></p>\n<p>这里王万祥能听懂，是汉语无疑了， 王万祥就按命令跪向前了。</p>\n<p>然后问话的画风就急转直下了。</p>\n<p>康熙问：</p>\n<p>“<strong>你是行伍出身么？</strong>”</p>\n<p>这应该是正式开始问话了，到这里康熙就开始用满语了。</p>\n<p>因为王万祥压根听不懂，一脸懵逼看康熙“不知所云”，茫然向旁边的侍卫进行眼神求助。</p>\n<p>但不得不说，王万祥是懂缓解尴尬的，也是会拍马屁的。</p>\n<p>因为他解释说：</p>\n<p>“<strong>一时不娴 <em>天 语</em> ，未曾答应。</strong>”</p>\n<p>好，好一个“天语”。</p>\n<p>于是旁边的侍卫，就给他翻译了康熙的问话，王万祥也进行了答复。</p>\n<p>康熙的问话，需要侍卫翻译；但王万祥的答话，则不需要翻译。</p>\n<p>问答结束，康熙又带着一种大臣、侍卫，出去射箭。</p>\n<p>王万祥也展示了箭法。</p>\n<p>康熙又就武艺问题，跟王万祥聊了个颠三倒四，双方问答的跟说相声一样。</p>\n<p>问：“<strong>尔弓有几个力气？</strong>”</p>\n<p>答：“<strong>有六个力气。</strong>”</p>\n<p>问：“<strong>尔会耍大刀么？</strong>”</p>\n<p>答：“<strong>不会。</strong>”</p>\n<p>问：“<strong>会耍梢子棍么？</strong>”</p>\n<p>答：“<strong>臣只会笨耍</strong>。”</p>\n<p>问：“<strong>怎么叫笨耍？</strong>”</p>\n<p>答：“<strong>臣每次临敌时，只是挥刀乱砍，不会耍花样子</strong>。”</p>\n<p>【这点倒是大实话，哪有那么多套路对打，都是乱拳打死老师傅。】</p>\n<p>这里的问话，虽然没什么营养，可能只是说闲话；但似乎都是用汉语问答的。</p>\n<p>虽然王万祥是被侍卫叫到康熙跟前演射的，但他没有明说康熙说“天语”，也没有向侍卫求助进行翻译。</p>\n<p>在王万祥答话结束后：</p>\n<p>“<strong>上点头，与侍卫说满话，想是说余老实。</strong>”</p>\n<p>那刚才演射后的问答，则应该就是说的汉话了。</p>\n<p>随后康熙让侍卫射箭，可能是想让他们跟王万祥较量下，结果五个侍卫，三个都射脱靶了。</p>\n<p>这下真的“<strong>射箭箭虚发</strong>”了。</p>\n<p>看得康熙和王万祥都很无语。</p>\n<p>康熙应该是压着怒火，人这么多也不好直接发飙，就对侍卫喷了一通垃圾话，当然肯定是用满语说的。</p>\n<p>毕竟有王万祥这个汉人武官在场。</p>\n<p>王万祥回忆：</p>\n<p>“<strong>上对射箭的侍卫做满话，想是说你们箭脱空，不害羞么？只见侍卫等回答彷徨。</strong>”</p>\n<p>然后就打发王万祥退下了。</p>\n<p>总结王万祥的这次见驾。</p>\n<p>第一次见驾，离得远，不知道康熙说的甚么话？</p>\n<p>但是听到康熙念自己名字了。</p>\n<p>这里应该跟兵部官说的是满语。</p>\n<p>第二次见驾，设宴问话，正式场合，全程满语问答。</p>\n<p>转场去射箭，属于私下交流场合，所以用汉语问答，都是些家常话。</p>\n<p>侍卫射箭丢了大脸，直接用满语开喷。</p>\n<blockquote>\n<p>作者：读书的小猹<br>链接：<a href=\"https://www.zhihu.com/question/20331441/answer/1923411592244098193\">https://www.zhihu.com/question/20331441/answer/1923411592244098193</a></p>\n</blockquote>\n","excerpt":"","more":"<blockquote>\n<p>王万祥，字瑞宇，号铁山，明崇祯十六年（1643年）出生于甘肃会宁。他出身贫寒，三岁时父亲去世，后随母亲投奔在王进宝军中当差的郭姑父。母亲病逝后，王万祥十五岁从戎，后因军功升至福建陆路提督，一生戎马四十余年，历经大小数十战，九死一生。康熙十二年（1673年），王万祥随西宁总兵王进宝前往平叛王辅臣的叛乱。在征战中，他屡立战功，被称为“飞将军”，并将亲身经历编撰成书《西征纪略》</p>\n</blockquote>\n<p>康熙二十四年三月，时任固原中营副将的王万祥，因平叛战功被升任定海镇总兵。</p>\n<p>并获得进京陛见的机会。</p>\n<p>瀛台见驾的时候，因为离得稍远，且主要是侍卫对他盘问，所以没听到康熙的其他言语。</p>\n<p>倒是听到康熙念他的名字了（还有其他武官一起见驾）。</p>\n<p>“<strong>皇上顾视数次，与兵部（官员）言我名字，盖汉人的名字。我内心自忖，既传呼我名字数次，便有眷注之意。</strong>”</p>\n<p>虽然不知道康熙说的其他话，但王万祥确实听到康熙念叨他名字了，而且听得很真切。</p>\n<p>至少名字应该是汉语说的。</p>\n<p>然后被侍卫询问，脱衣展示厮杀时留的伤口，如孙权周泰故事。</p>\n<p>似乎康熙对此不感兴趣，等王万祥展示完伤疤，抬头一看，康熙已经跟其他官员起驾走了。</p>\n<p>王万祥得空看了一遭瀛台景致，然后也退下了。</p>\n<p>后得旨又转任兴化镇总兵。</p>\n<p>次日被引至乾清门谢恩，又到景山内前殿赐宴，一同出席的有佟国维等。</p>\n<p>康熙来了后，见驾行礼，赐茶，赐宴，似乎没有交流，也没有发言。</p>\n<p>开宴吃个差不多后，康熙让王万祥近前问话。</p>\n<p>但王万祥跪的稍远，康熙就一直说：</p>\n<p><strong>“向前些。”“在近前。”</strong></p>\n<p>这里王万祥能听懂，是汉语无疑了， 王万祥就按命令跪向前了。</p>\n<p>然后问话的画风就急转直下了。</p>\n<p>康熙问：</p>\n<p>“<strong>你是行伍出身么？</strong>”</p>\n<p>这应该是正式开始问话了，到这里康熙就开始用满语了。</p>\n<p>因为王万祥压根听不懂，一脸懵逼看康熙“不知所云”，茫然向旁边的侍卫进行眼神求助。</p>\n<p>但不得不说，王万祥是懂缓解尴尬的，也是会拍马屁的。</p>\n<p>因为他解释说：</p>\n<p>“<strong>一时不娴 <em>天 语</em> ，未曾答应。</strong>”</p>\n<p>好，好一个“天语”。</p>\n<p>于是旁边的侍卫，就给他翻译了康熙的问话，王万祥也进行了答复。</p>\n<p>康熙的问话，需要侍卫翻译；但王万祥的答话，则不需要翻译。</p>\n<p>问答结束，康熙又带着一种大臣、侍卫，出去射箭。</p>\n<p>王万祥也展示了箭法。</p>\n<p>康熙又就武艺问题，跟王万祥聊了个颠三倒四，双方问答的跟说相声一样。</p>\n<p>问：“<strong>尔弓有几个力气？</strong>”</p>\n<p>答：“<strong>有六个力气。</strong>”</p>\n<p>问：“<strong>尔会耍大刀么？</strong>”</p>\n<p>答：“<strong>不会。</strong>”</p>\n<p>问：“<strong>会耍梢子棍么？</strong>”</p>\n<p>答：“<strong>臣只会笨耍</strong>。”</p>\n<p>问：“<strong>怎么叫笨耍？</strong>”</p>\n<p>答：“<strong>臣每次临敌时，只是挥刀乱砍，不会耍花样子</strong>。”</p>\n<p>【这点倒是大实话，哪有那么多套路对打，都是乱拳打死老师傅。】</p>\n<p>这里的问话，虽然没什么营养，可能只是说闲话；但似乎都是用汉语问答的。</p>\n<p>虽然王万祥是被侍卫叫到康熙跟前演射的，但他没有明说康熙说“天语”，也没有向侍卫求助进行翻译。</p>\n<p>在王万祥答话结束后：</p>\n<p>“<strong>上点头，与侍卫说满话，想是说余老实。</strong>”</p>\n<p>那刚才演射后的问答，则应该就是说的汉话了。</p>\n<p>随后康熙让侍卫射箭，可能是想让他们跟王万祥较量下，结果五个侍卫，三个都射脱靶了。</p>\n<p>这下真的“<strong>射箭箭虚发</strong>”了。</p>\n<p>看得康熙和王万祥都很无语。</p>\n<p>康熙应该是压着怒火，人这么多也不好直接发飙，就对侍卫喷了一通垃圾话，当然肯定是用满语说的。</p>\n<p>毕竟有王万祥这个汉人武官在场。</p>\n<p>王万祥回忆：</p>\n<p>“<strong>上对射箭的侍卫做满话，想是说你们箭脱空，不害羞么？只见侍卫等回答彷徨。</strong>”</p>\n<p>然后就打发王万祥退下了。</p>\n<p>总结王万祥的这次见驾。</p>\n<p>第一次见驾，离得远，不知道康熙说的甚么话？</p>\n<p>但是听到康熙念自己名字了。</p>\n<p>这里应该跟兵部官说的是满语。</p>\n<p>第二次见驾，设宴问话，正式场合，全程满语问答。</p>\n<p>转场去射箭，属于私下交流场合，所以用汉语问答，都是些家常话。</p>\n<p>侍卫射箭丢了大脸，直接用满语开喷。</p>\n<blockquote>\n<p>作者：读书的小猹<br>链接：<a href=\"https://www.zhihu.com/question/20331441/answer/1923411592244098193\">https://www.zhihu.com/question/20331441/answer/1923411592244098193</a></p>\n</blockquote>\n"},{"title":"一首小诗","date":"2025-09-12T02:13:15.000Z","_content":"Theory is we know why,\n              but it doesn't work.\n\nPractice is it works,\n              but we don't know why.\n\nIn our lab, theory and practice is well combined...\n\nNothing works and nobody knows why\n","source":"_posts/一首小诗.md","raw":"---\ntitle: 一首小诗\ndate: 2025-09-12 10:13:15\ncategories:\n  - 随笔\ntags:\n  - 随笔杂记\n---\nTheory is we know why,\n              but it doesn't work.\n\nPractice is it works,\n              but we don't know why.\n\nIn our lab, theory and practice is well combined...\n\nNothing works and nobody knows why\n","slug":"一首小诗","published":1,"updated":"2025-10-11T09:50:01.411Z","_id":"cmfs6wn930000qb9lcpy09iau","comments":1,"layout":"post","photos":[],"content":"<p>Theory is we know why,<br>              but it doesn’t work.</p>\n<p>Practice is it works,<br>              but we don’t know why.</p>\n<p>In our lab, theory and practice is well combined…</p>\n<p>Nothing works and nobody knows why</p>\n","excerpt":"","more":"<p>Theory is we know why,<br>              but it doesn’t work.</p>\n<p>Practice is it works,<br>              but we don’t know why.</p>\n<p>In our lab, theory and practice is well combined…</p>\n<p>Nothing works and nobody knows why</p>\n"}],"PostAsset":[{"_id":"source/_posts/TMU硕士申请调研/课程.png","slug":"课程.png","post":"cmf9mvzss0001ad9l6adhdu5p","modified":0,"renderable":0},{"_id":"source/_posts/二十年前的相机/内部.jpg","slug":"内部.jpg","post":"cmf9mvzsv0006ad9l65l0eowv","modified":0,"renderable":0},{"_id":"source/_posts/二十年前的相机/包装.jpg","slug":"包装.jpg","post":"cmf9mvzsv0006ad9l65l0eowv","modified":0,"renderable":0},{"_id":"source/_posts/二十年前的相机/照片.jpg","slug":"照片.jpg","post":"cmf9mvzsv0006ad9l65l0eowv","modified":0,"renderable":0},{"_id":"source/_posts/二十年前的相机/相机.jpg","slug":"相机.jpg","post":"cmf9mvzsv0006ad9l65l0eowv","modified":0,"renderable":0}],"PostCategory":[{"post_id":"cmf9n1sx80000gn9l2qeg899n","category_id":"cmf9mvzsu0003ad9l3cmyhcus","_id":"cmf9n1sxa0002gn9lbba8a1yr"},{"post_id":"cmf9mvzsv0006ad9l65l0eowv","category_id":"cmgm3eywy0002y69l3flr3rff","_id":"cmgm3eywz0003y69ld215akzu"},{"post_id":"cmf9mvzsv0005ad9lbbo7d19c","category_id":"cmgm3gosy0004y69l94vk1245","_id":"cmgm3gosz0005y69l64vo0pno"},{"post_id":"cmfs6wn930000qb9lcpy09iau","category_id":"cmgm3gpej0006y69l1ndi4oap","_id":"cmgm3gpej0007y69le62a5q0r"},{"post_id":"cmf9mvzst0002ad9l90ufhg6v","category_id":"cmgm3gpej0006y69l1ndi4oap","_id":"cmgm3ikep0008y69l60elgs6o"},{"post_id":"cmf9mvzss0001ad9l6adhdu5p","category_id":"cmgm3gpej0006y69l1ndi4oap","_id":"cmgm3j6d60009y69l8k0v77ca"}],"PostTag":[{"post_id":"cmf9mvzss0001ad9l6adhdu5p","tag_id":"cmf9mvzsv0004ad9lg3x17vpo","_id":"cmf9mvzsw0009ad9l9eeaagd5"},{"post_id":"cmf9mvzst0002ad9l90ufhg6v","tag_id":"cmf9mvzsv0004ad9lg3x17vpo","_id":"cmf9mvzsx000dad9l34y5hfab"},{"post_id":"cmf9mvzsv0005ad9lbbo7d19c","tag_id":"cmf9mvzsx000gad9l8usj7r62","_id":"cmf9mvzsx000kad9lhm7q40ts"},{"post_id":"cmf9mvzsv0006ad9l65l0eowv","tag_id":"cmf9mvzsx000iad9l0z7ehx71","_id":"cmf9mvzsy000lad9ld7z7gpgi"},{"post_id":"cmf9n1sx80000gn9l2qeg899n","tag_id":"cmf9mvzsx000cad9laim14rvs","_id":"cmf9n1sxa0001gn9lecf454wg"},{"post_id":"cmfs6wn930000qb9lcpy09iau","tag_id":"cmfs6wn950001qb9l3p1952pl","_id":"cmfs6wn960002qb9lgcq77yup"}],"Tag":[{"name":"留学申请","_id":"cmf9mvzsv0004ad9lg3x17vpo"},{"name":"转载","_id":"cmf9mvzsx000cad9laim14rvs"},{"name":"pytorch","_id":"cmf9mvzsx000gad9l8usj7r62"},{"name":"摄影","_id":"cmf9mvzsx000iad9l0z7ehx71"},{"name":"随笔杂记","_id":"cmfs6wn950001qb9l3p1952pl"}]}}